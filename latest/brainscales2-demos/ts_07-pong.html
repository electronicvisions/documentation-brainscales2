<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Pong &mdash; BrainScaleS-2 Documentation 0.0.1 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/visions.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Complex Neuron Dynamics with a Silicon Adaptive Exponential Integrate-and-Fire Neuron" href="ts_08-adex_complex_dynamics.html" />
    <link rel="prev" title="Exploring the dynamic range" href="ts_06-dynamic_range.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            BrainScaleS-2 Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Demos &amp; Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="tutorial.html">Demos and Examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ts_00-single_neuron.html">BrainScaleS-2 single neuron experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_01-superspike.html">Learning with the SuperSpike rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_02-plasticity_rate_coding.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_03-multicompartment.html">Multicompartmental Neurons</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_04-mc_genetic_algorithms.html">How to use Genetic Algorithms to automatically parameterize BrainScaleS-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_05-yin_yang.html">Training an SNN on BrainScaleS-2 with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_06-dynamic_range.html">Exploring the dynamic range</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Pong</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#encoding">Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#learning-rule">Learning rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="#implementation">Implementation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#credits">Credits</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="ts_08-adex_complex_dynamics.html">Complex Neuron Dynamics with a Silicon Adaptive Exponential Integrate-and-Fire Neuron</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_09-inside_realtime_hook.html">Demonstration of inside realtime hook</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_10-multiple_configs.html">Demonstration of multiple chip-reconfigurations during an experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_11-plasticity_homeostasis.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_12-hxtorch_snn_intro.html">hxtorch.snn Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_13-network_partitioning.html">Partitioning of Feedforward SNNs</a></li>
<li class="toctree-l3"><a class="reference internal" href="tp_00-introduction.html">Introduction to matrix multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="tp_01-properties.html">Exploring the analog MAC operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="tp_02-yin_yang.html">Train DNNs on BrainScaleS-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="nmpi_00-non_interactive_queue_runner.html">Introduction to the non-interactive queue runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#executing-the-notebooks">Executing the Notebooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#shared-hardware-resources">Shared Hardware Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#final-test-hardware-execution">Final test: Hardware Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="girlsday.html">Wie verarbeitet unser Gehirn Informationen?</a></li>
<li class="toctree-l2"><a class="reference internal" href="fortgeschrittenen_praktikum.html">Welcome to the Advanced Physics Lab for Physicists by the Electronic Vision(s) Group</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../software_components.html">Software Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">BrainScaleS-2 Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Welcome to the BrainScaleS-2 Demos &amp; Examples!</a></li>
          <li class="breadcrumb-item"><a href="tutorial.html">Welcome to the BrainScaleS-2 Tutorial</a></li>
      <li class="breadcrumb-item active">Pong</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/brainscales2-demos/ts_07-pong.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">enum</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">import</span> <span class="nn">textwrap</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">struct</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">import</span> <span class="nn">IPython.display</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">quantities</span> <span class="k">as</span> <span class="nn">pq</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">dlens_vx_v3</span> <span class="kn">import</span> <span class="n">halco</span><span class="p">,</span> <span class="n">hal</span><span class="p">,</span> <span class="n">sta</span><span class="p">,</span> <span class="n">lola</span>

<span class="kn">import</span> <span class="nn">pynn_brainscales.brainscales2</span> <span class="k">as</span> <span class="nn">pynn</span>

<span class="kn">from</span> <span class="nn">_static.common.helpers</span> <span class="kn">import</span> <span class="n">save_nightly_calibration</span>
<span class="kn">from</span> <span class="nn">_static.tutorial.pong_demo_helpers</span> <span class="kn">import</span> <span class="n">Parameters</span><span class="p">,</span> <span class="n">ExperimentData</span><span class="p">,</span> <span class="n">PongGame</span>

<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">suppress</span>
<span class="k">with</span> <span class="n">suppress</span><span class="p">(</span><span class="ne">IOError</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;_static/matplotlibrc&quot;</span><span class="p">)</span>

<span class="c1"># setup shared connection to hardware</span>
<span class="kn">from</span> <span class="nn">_static.common.helpers</span> <span class="kn">import</span> <span class="n">setup_hardware_client</span>
<span class="n">setup_hardware_client</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="pong">
<h1>Pong<a class="headerlink" href="#pong" title="Permalink to this headline"></a></h1>
<p>This notebook aims at learning the Pong game. A ball is played between
two players, mimicking table tennis. Each player controls a paddle that
reflects the ball, as shown below. We will train a neural network that
controls the right player.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># display a perfectly played pong game - without any neural network so far.</span>
<span class="n">pong_game</span> <span class="o">=</span> <span class="n">PongGame</span><span class="p">(</span><span class="n">demo</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pong_game</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>  <span class="c1"># runs a perfect game</span>
<span class="n">pong_game</span><span class="o">.</span><span class="n">animate</span><span class="p">()</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/pong_demo_game_overview.png"><img alt="Pong game" class="solution align-center" src="../_images/pong_demo_game_overview.png" style="width: 1600px;" /></a>
<div class="section" id="encoding">
<h2>Encoding<a class="headerlink" href="#encoding" title="Permalink to this headline"></a></h2>
<p>BrainScaleS-2 will learn to control one of the paddles to track the
pong ball at all times, thus learning to play the game.
The chip is supplied with the vertical
position of the ball - encoded by a uniform spiketrain to an input
neuron (left column “input spikes” in figure below). A matrix of
excitatory synapses densely connects the input to output neurons (shown
as green dots in figure below, the intensity represents the weight of
the synapse). The paddle moves to the position encoded by the
most-active output neuron (row “output spikes” below the neurons in
figure below). The network does not have a concept of time, it will only
return a paddle position for an input ball position. Thus, we will query
thet network regularly to have the paddle track the ball. Both the ball
and the paddle have a certain size, i.e. the input spikes are
distributed to more than one synapse row and the most-active neuron can
be a bit besides the center of the ball.</p>
<p>The ball and paddle positions are mapped to the synapse matrix linearly,
so a diagonal matrix will be able to play the game perfectly - that is,
as long as the paddle moves quickly with respect to the ball, which we
allow here. In the figure below, we indicate this perfect paddle
position by the red arrow through the synapse matrix. In this example
however, the most-active neuron is outside the paddle size, so the
paddle would move further to the right and would miss the ball.</p>
<a class="reference internal image-reference" href="../_images/pong_encoding.png"><img alt="Encoding and reward for pong game" src="../_images/pong_encoding.png" style="width: 1000px;" /></a>
</div>
<div class="section" id="learning-rule">
<h2>Learning rule<a class="headerlink" href="#learning-rule" title="Permalink to this headline"></a></h2>
<p>We use reward-modulated spike timing dependent plasticity (R-STDP)
<a class="reference external" href="https://journals.physiology.org/doi/full/10.1152/jn.00364.2007">[Michael and Fairhall,
2007]</a>
to learn the game, as described in the following. This implementation is
close to <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2019.00260/full">Timo Wunderlich et
al. (2019)</a>,
but here we do not go as far as implementing the whole pong game on the
chip’s digital microprocessor, we will only execute the learning
algorithm locally on chip. Furthermore, the network now runs on a much
larger synapse matrix, which has required a few changes.</p>
<p>Training is controlled by maximizing a reward. The reward is a metric
for the performance of the player in a given scenario, i.e. the spike
counts per neuron for a certain ball position. Spikes of neurons closer
to the center of the paddle are rewarded more strongly, spikes of neurons
that still result in the ball hitting the paddle increase the
reward only slightly, and spikes outside the width of the paddle
decrease the reward. In the
figure above, we plot the reward multiplicator, which yields positive
rewards only in the region where the paddle should have moved to. And
below that we show the contributions of the individual neurons to the
total reward, which are the product of the spike count and the reward
multiplier.</p>
<p>For each network run, we calculate the instantaneous reward and compare
it to an exponentially weighted expected reward from the previous runs.
The strength of the weight update is scaled with this reward delta,
which can be positive or negative. If the network performs better than
before, the weights will be updated according to the measured
correlation between pre- and postsynaptic spikes (STDP). In case the
network performs worse than before, the weight update is inverted. The
weight update <span class="math notranslate nohighlight">\(\Delta w_{ij}\)</span> is given by the following learning
rule, where <span class="math notranslate nohighlight">\(\beta\)</span> is the learning rate, <span class="math notranslate nohighlight">\(R\)</span> the
instantaneous reward, <span class="math notranslate nohighlight">\(\bar{R}\)</span> the expected reward from previous
runs, the index <span class="math notranslate nohighlight">\(k\)</span> denotes the ball position, and
<span class="math notranslate nohighlight">\(\text{corr}_{ij}\)</span> is the causal correlation observed by each
synapse:</p>
<div class="math notranslate nohighlight">
\[\Delta w_{ij} = \beta \cdot (R_k - \bar{R_k}) \cdot \text{corr}_{ij}\]</div>
<p>During training, we present all possible ball positions once in what we
call an epoch. For all individual ball positions, we apply random noise
to the neurons, implemented as a synapse row with randomly drawn
weights. This allows for exploring all options within the synapse
matrix. The reward and correlation are calculated based on all
postsynaptic spikes, including those injected by noise - so the weights
will increase in case the random noise pattern matches the desired
outcome.</p>
<p>Noise is required for this training algorithm to work, as it allows
exploration in the beginning of the training. During the training, we
linearly decrease the injected noise amplitude. This is implemented as
decreasing the standard deviation of the noise weights, which are drawn
from approximately a normal distribution. In order to have a rather
sparse noise distribution, its mean is shifted to below zero, and all
weights below zero are clipped. During initial training, the output
spikes are mainly generated by noise, while finally, they are mainly
generated by trained weights.</p>
<p>Lastly, at the end of an epoch, we employ a homeostasis rule to control
the total number of spikes. In case a neuron spikes too often within an
epoch, all weights of its column of input synapses will be decreased (or
increased if it spikes not often enough). In the beginning of the
training, we exceed the homeostasis target spike count already as a
result of noise input. This means that only fast-growing weights will be
able to persist initially.</p>
<p>To summarize, within one epoch, we present all possible input ball
positions once. For each ball position, a new set of noise weights is
drawn, the network is run, the weights are updated based on the
reward-modulated STDP rule, and the expected reward is updated with the
newly observed reward. Finally, the homeostasis rule is applied based on
the total spike counts within the epoch.</p>
</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline"></a></h2>
<p>The following code implements this learning rule in PyNN. We send the
spike inputs for an epoch from the host, but handle the learning rule on
the plasticity-processing unit (PPU), locally on the chip. The PPU will
read the spike counters, calculate a reward, compare it to the
previously obtained rewards to get a weight update rate, and update the
weights based on measured causal correlation. Before processing the next
input sample, the PPU draws new random weights for the noise row, and
resets spike counters and correlation data.</p>
<p>Since the PPU handles all training, we train multiple epochs
in one PyNN call. The number of epochs trained in one hardware run is
only limited by the maximum runtime of PyNN. There is no reason to keep
the host computer in the loop, we only read back the updated weights
from the chip after each PyNN run.</p>
<p>In the following cell, we define parameters for the experiment. Feel
free to modify them and explore! The default parameters should learn the
game rather quickly, within some 300 epochs. (After changing parameters,
you need to re-execute all cells in the rest of the notebook, for the
changes to be effective.)</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create an instance of the dataclass `Parameters`, which is used</span>
<span class="c1"># throughout this notebook. The values are set in this cell.</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">Parameters</span><span class="p">()</span>

<span class="c1"># Number of total epochs, in which noise is reduced from start to end.</span>
<span class="c1"># The notebook will not execute all those by default, we will train</span>
<span class="c1"># only a few hundred epochs at the end.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">noise_range_epochs</span> <span class="o">=</span> <span class="mi">500</span>

<span class="c1"># Number of input rows.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Number of output neurons.</span>
<span class="c1"># Fundamentally, the pong task works with an equal number of inputs</span>
<span class="c1"># and outputs. In case you add more outputs, the weights of</span>
<span class="c1"># synapses in the additional columns will remain low.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Select distribution of input events across multiple rows.</span>
<span class="c1"># In order to not depend on all correlation sensors etc. working</span>
<span class="c1"># perfectly, we distribute the input events across multiple synapse</span>
<span class="c1"># rows. This list contains the relative event rates for further</span>
<span class="c1"># rows. Example: A configuration `input_distribution = [1, 0.7, 0.3]`</span>
<span class="c1"># will send the full rate to the middle row, 0.7 times the full rate</span>
<span class="c1"># to the rows one above and below, and 0.3 times the full rate to the</span>
<span class="c1"># rows two above and below.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">input_distribution</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>

<span class="c1"># Number of input events sent to middle (&quot;target&quot;) input row.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">n_events</span> <span class="o">=</span> <span class="mi">140</span>

<span class="c1"># Inter-spike interval for input events in middle input row.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">wait_between_events</span> <span class="o">=</span> <span class="mf">4.20</span> <span class="o">*</span> <span class="n">pq</span><span class="o">.</span><span class="n">us</span>

<span class="c1"># Inter-spike interval for noise events. The noise is applied for</span>
<span class="c1"># the same time-duration as the inputs.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">wait_between_noise</span> <span class="o">=</span> <span class="mf">3.5</span> <span class="o">*</span> <span class="n">pq</span><span class="o">.</span><span class="n">us</span>

<span class="c1"># Standard deviation of noise weight distribution. The noise weights</span>
<span class="c1"># are drawn from an approximated normal distribution. The standard</span>
<span class="c1"># deviation is reduced linearly during training, from the configured</span>
<span class="c1"># start to end values.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">noise_range_start</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">noise_range_end</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># Reward for each neuron depending on the distance from the target</span>
<span class="c1"># neuron. The number of spikes of each neuron is multiplied with the</span>
<span class="c1"># factor given here, and the sum of these products is the reward for</span>
<span class="c1"># an experiment run.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">{</span>  <span class="c1"># dict key: distance from target; value: reward factor</span>
    <span class="mi">0</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># at target neuron</span>
    <span class="mi">1</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>  <span class="c1"># 1 left or right of target</span>
    <span class="mi">2</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># 2 left or right of target</span>
    <span class="mi">3</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>  <span class="c1"># ...</span>
    <span class="mi">4</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;elsewhere&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
    <span class="c1"># Reward &quot;elsewhere&quot; must be below 0. All rewards below zero are</span>
    <span class="c1"># assumed to have missed the paddle, zero and greater rewards are</span>
    <span class="c1"># assumed to have hit the paddle.</span>
<span class="p">}</span>

<span class="c1"># Learning rate.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Target spikes per column in an epoch for homeostasis.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">homeostasis_target</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span>

<span class="c1"># Update rate for homeostasis, in weight LSB.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">homeostasis_rate</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">parameters</span><span class="o">.</span><span class="n">homeostasis_target</span>

<span class="c1"># Reward decay: Update rate of average reward in each epoch. The reward</span>
<span class="c1"># is updated with the new, instantaneous reward in each epoch. A high</span>
<span class="c1"># decay means that the average reward closely follows the state in each</span>
<span class="c1"># epoch, a low decay means that the average reward changes only slowly</span>
<span class="c1"># with the new results in each epoch.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">reward_decay</span> <span class="o">=</span> <span class="mf">0.5</span>

<span class="c1"># Number of epochs that are executed initially without learning, in</span>
<span class="c1"># order to initialize the average reward.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">reward_initialization_phase</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1">### Timing properties - expect broken results when reducing them below the required time!</span>
<span class="c1"># Scheduled time for initialization, such as correlation resets</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">init_duration</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">pq</span><span class="o">.</span><span class="n">ms</span>

<span class="c1"># Scheduled time for handling plasticity kernel</span>
<span class="c1"># You may need to increase this value when using a higher number of inputs.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">plasticity_duration</span> <span class="o">=</span> <span class="mf">2.5</span> <span class="o">*</span> <span class="n">pq</span><span class="o">.</span><span class="n">ms</span>

<span class="c1"># Number of epochs executed within one pynn.run() call.</span>
<span class="c1"># Note: learning rate is only updated at compile-time, i.e.</span>
<span class="c1"># will not be updated during the epochs within a PyNN run.</span>
<span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># set variables that will be used later in this script</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">)</span>
<span class="n">logical_weights</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ExperimentData</span><span class="p">(</span><span class="n">epochs_per_run</span><span class="o">=</span><span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)</span>
</pre></div>
</div>
<p>We now define two plasticity rules: <code class="docutils literal notranslate"><span class="pre">NoiseSynapseRule</span></code> handles
initialization and draws a new random distribution of noise weights,
while <code class="docutils literal notranslate"><span class="pre">PlasticityRule</span></code> handles the reward-modulated STDP learning
rule.</p>
<p>Both plasticity rules are Python classes that generate and return a
<code class="docutils literal notranslate"><span class="pre">c++</span></code> code snippet that will be compiled and executed on the PPU. For
readability, we print the returned code with <code class="docutils literal notranslate"><span class="pre">c++</span></code> syntax highlighting
below the cell.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NoiseSynapseRule</span><span class="p">(</span><span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Draw a new set of noise weights after each input row, and do further</span>
<span class="sd">    initialization tasks.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">generate_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate plasticity rule kernel to be compiled into PPU program.</span>

<span class="sd">        :return: PPU-code of plasticity-rule kernel as string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        #include &quot;grenade/vx/ppu/synapse_array_view_handle.h&quot;</span>
<span class="s2">        #include &quot;grenade/vx/ppu/neuron_view_handle.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/correlation.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/dls.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/vector_row.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/vector_if.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/parallel_rng.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/reset_neurons.h&quot;</span>
<span class="s2">        #include &quot;stadls/vx/v3/ppu/write.h&quot;</span>

<span class="s2">        using namespace grenade::vx::ppu;</span>
<span class="s2">        using namespace libnux::vx;</span>

<span class="s2">        // PPU currently executing this code (top/bottom).</span>
<span class="s2">        extern volatile PPUOnDLS ppu;</span>

<span class="s2">        /**</span>
<span class="s2">         * Initialize the random number generator by selecting a seed</span>
<span class="s2">         * and drawing a few random numbers initially.</span>
<span class="s2">         */</span>
<span class="s2">        class RNGInit</span>
<span class="s2">        </span><span class="se">{{</span>
<span class="s2">            public:</span>
<span class="s2">            RNGInit()</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                parallel_rng_seed(VectorRowMod8(</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">256</span><span class="p">)</span><span class="si">}</span><span class="s2">));</span>
<span class="s2">                for (size_t i = 0; i &lt; 234 + </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">                    parallel_rng_rand&lt;VectorRowMod8&gt;();</span>
<span class="s2">            </span><span class="se">}}</span>
<span class="s2">        </span><span class="se">}}</span><span class="s2">;</span>
<span class="s2">        RNGInit rng_init;</span>

<span class="s2">        void PLASTICITY_RULE_KERNEL(</span>
<span class="s2">            std::array&lt;SynapseArrayViewHandle, 1&gt;&amp; synapses,</span>
<span class="s2">            std::array&lt;NeuronViewHandle, 0&gt;&amp; /* neurons */)</span>
<span class="s2">        </span><span class="se">{{</span>
<span class="s2">            // only continue if code is executed on the correct PPU</span>
<span class="s2">            if (synapses[0].hemisphere != ppu) </span><span class="se">{{</span>
<span class="s2">                return;</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            // pick a new row of random weights:</span>
<span class="s2">            // Use 12 random vectors with a uniform distribution and summarize</span>
<span class="s2">            // them as approximation of a normal distribution. After bit-shifting,</span>
<span class="s2">            // the sum of the vectors represents a distribution with roughly</span>
<span class="s2">            // a mean of -4.5 and a standard deviation of 32.</span>
<span class="s2">            VectorRowFracSat16 accumulator;</span>
<span class="s2">            for (size_t i = 0; i &lt; 12; ++i)</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                accumulator += VectorRowFracSat16(</span>
<span class="s2">                    parallel_rng_rand&lt;VectorRowFracSat8&gt;() &gt;&gt; 3);</span>
<span class="s2">                // Draw more vectors to avoid summarizing correlated ones:</span>
<span class="s2">                // Draw at least the number of used bits, since we only</span>
<span class="s2">                // get one new random bit per draw</span>
<span class="s2">                for (size_t j = 0; j &lt; 13; ++j)</span>
<span class="s2">                    parallel_rng_rand&lt;VectorRowFracSat8&gt;();</span>
<span class="s2">            </span><span class="se">}}</span>
<span class="s2">            VectorRowFracSat8 accumulator_8 = VectorRowFracSat8(accumulator - 6);</span>
<span class="s2">            VectorRowFracSat8 random = VectorRowFracSat8(</span>
<span class="s2">                accumulator_8 * (</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">get_noise_range</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="si">}</span><span class="s2"> * 4));</span>

<span class="s2">            random = vector_if(</span>
<span class="s2">                random, VectorIfCondition::lesser, VectorRowFracSat8(0), random);</span>
<span class="s2">            random = vector_if(</span>
<span class="s2">                random - 63, VectorIfCondition::greater, VectorRowFracSat8(63), random);</span>
<span class="s2">            for (size_t row = 0; row &lt; synapses[0].rows.size(); ++row) </span><span class="se">{{</span>
<span class="s2">                synapses[0].set_weights(VectorRowMod8(random), row);</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            // prepare for next correlation experiment:</span>
<span class="s2">            reset_neurons();</span>

<span class="s2">            // reset spike counters</span>
<span class="s2">            for (size_t i = 0; i &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                auto coord = halco::hicann_dls::vx::v3::AtomicNeuronOnDLS(</span>
<span class="s2">                    halco::hicann_dls::vx::v3::NeuronColumnOnDLS(i),</span>
<span class="s2">                    halco::hicann_dls::vx::v3::NeuronRowOnDLS()</span>
<span class="s2">                ).toSpikeCounterResetOnDLS();</span>
<span class="s2">                stadls::vx::v3::ppu::write(</span>
<span class="s2">                    coord, haldls::vx::v3::SpikeCounterReset());</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            reset_all_correlations();</span>
<span class="s2">        </span><span class="se">}}</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">)</span>

<span class="c1"># create a timer that controls when this plasticity rule is executed</span>
<span class="n">init_timer</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span>
    <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">period</span><span class="o">=</span><span class="n">parameters</span><span class="o">.</span><span class="n">row_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
    <span class="n">num_periods</span><span class="o">=</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)</span>

<span class="c1"># print returned PPU kernel code with c++ syntax highlighting</span>
<span class="k">class</span> <span class="nc">DemoRule</span><span class="p">(</span><span class="n">NoiseSynapseRule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="n">ppu_code</span> <span class="o">=</span> <span class="n">DemoRule</span><span class="p">()</span><span class="o">.</span><span class="n">generate_kernel</span><span class="p">()</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display_markdown</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;``` c++ </span><span class="se">\n</span><span class="si">{</span><span class="n">ppu_code</span><span class="si">}</span><span class="se">\n</span><span class="s2">```&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PlasticityRule</span><span class="p">(</span><span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update synapse weights according to STDP learning rule.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">timer</span><span class="p">:</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Timer</span><span class="p">,</span> <span class="n">same_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize plastic synapse with execution timing information,</span>
<span class="sd">        hyperparameters and initial weight.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">observables</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;rewards&quot;</span><span class="p">:</span> <span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="o">.</span><span class="n">ObservableArray</span><span class="p">(),</span>
            <span class="s2">&quot;success&quot;</span><span class="p">:</span> <span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="o">.</span><span class="n">ObservableArray</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">observables</span><span class="p">[</span><span class="s2">&quot;rewards&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> \
            <span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="o">.</span><span class="n">ObservableArray</span><span class="o">.</span><span class="n">Type</span><span class="o">.</span><span class="n">uint8</span>
        <span class="n">observables</span><span class="p">[</span><span class="s2">&quot;rewards&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="n">observables</span><span class="p">[</span><span class="s2">&quot;success&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">type</span> <span class="o">=</span> \
            <span class="n">pynn</span><span class="o">.</span><span class="n">PlasticityRule</span><span class="o">.</span><span class="n">ObservableArray</span><span class="o">.</span><span class="n">Type</span><span class="o">.</span><span class="n">uint8</span>
        <span class="n">observables</span><span class="p">[</span><span class="s2">&quot;success&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">timer</span><span class="o">=</span><span class="n">timer</span><span class="p">,</span> <span class="n">observables</span><span class="o">=</span><span class="n">observables</span><span class="p">,</span> <span class="n">same_id</span><span class="o">=</span><span class="n">same_id</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate plasticity rule kernel to be compiled into PPU program.</span>

<span class="sd">        :return: PPU-code of plasticity-rule kernel as string.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ppucode</span> <span class="o">=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        #include &lt;algorithm&gt;</span>
<span class="s2">        #include &quot;grenade/vx/ppu/synapse_array_view_handle.h&quot;</span>
<span class="s2">        #include &quot;grenade/vx/ppu/neuron_view_handle.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/correlation.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/dls.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/vector_row.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/vector_if.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/mailbox.h&quot;</span>
<span class="s2">        #include &quot;libnux/vx/time.h&quot;</span>
<span class="s2">        #include &quot;stadls/vx/v3/ppu/read.h&quot;</span>

<span class="s2">        using namespace grenade::vx::ppu;</span>
<span class="s2">        using namespace libnux::vx;</span>

<span class="s2">        /**</span>
<span class="s2">         * PPU currently executing this code (top/bottom).</span>
<span class="s2">         */</span>
<span class="s2">        extern volatile PPUOnDLS ppu;</span>

<span class="s2">        /**</span>
<span class="s2">         * Mean rewards, updated exponentially each epoch</span>
<span class="s2">         */</span>
<span class="s2">        float mean_rewards[</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="si">}</span><span class="s2">] = </span><span class="se">{{</span>
<span class="s2">            </span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">rewards</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span><span class="si">}</span>
<span class="s2">        </span><span class="se">}}</span><span class="s2">;</span>

<span class="s2">        /**</span>
<span class="s2">         * Baseline reads from correlation sensors, one per column.</span>
<span class="s2">         */</span>
<span class="s2">        VectorRowMod8 get_baselines()</span>
<span class="s2">        </span><span class="se">{{</span>
<span class="s2">            reset_all_correlations();</span>

<span class="s2">            VectorRowMod16 accumulator(0);</span>
<span class="s2">            for (size_t row = 0; row &lt; 256; ++row)</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                VectorRowMod8 result;</span>
<span class="s2">                get_causal_correlation(&amp;result.even.data, &amp;result.odd.data, row);</span>
<span class="s2">                accumulator += static_cast&lt;VectorRowMod16&gt;(result);</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            return VectorRowMod8(accumulator &gt;&gt; 8);</span>
<span class="s2">        </span><span class="se">}}</span>
<span class="s2">        VectorRowMod8 correlation_baselines = get_baselines();</span>

<span class="s2">        /**</span>
<span class="s2">         * Accumulated spikes per neuron (per epoch).</span>
<span class="s2">         */</span>
<span class="s2">        uint16_t all_spikes[</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">] = </span><span class="se">{{</span>
<span class="s2">            </span><span class="si">{</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;0&quot;</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">)])</span><span class="si">}</span><span class="s2"> </span><span class="se">}}</span><span class="s2">;</span>

<span class="s2">        /**</span>
<span class="s2">         * Currently active input row.</span>
<span class="s2">         */</span>
<span class="s2">        size_t current_row = 0;</span>

<span class="s2">        VectorRowFracSat8 check_boundaries(VectorRowFracSat8 vec)</span>
<span class="s2">        </span><span class="se">{{</span>
<span class="s2">            vec = vector_if(</span>
<span class="s2">                vec, VectorIfCondition::greater,</span>
<span class="s2">                vec, VectorRowFracSat8(0));</span>
<span class="s2">            vec = vector_if(</span>
<span class="s2">                vec - 63, VectorIfCondition::greater,</span>
<span class="s2">                VectorRowFracSat8(63), vec);</span>

<span class="s2">            return vec;</span>
<span class="s2">        </span><span class="se">}}</span>

<span class="s2">        void PLASTICITY_RULE_KERNEL(</span>
<span class="s2">            std::array&lt;SynapseArrayViewHandle, 1&gt;&amp; synapses,</span>
<span class="s2">            std::array&lt;NeuronViewHandle, 0&gt;&amp; /* neurons */,</span>
<span class="s2">            Recording&amp; recording)</span>
<span class="s2">        </span><span class="se">{{</span>
<span class="s2">            // only continue if code is executed on the correct PPU</span>
<span class="s2">            if (synapses[0].hemisphere != ppu) </span><span class="se">{{</span>
<span class="s2">                return;</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            recording.time = 0;</span>

<span class="s2">            // generate reward vector for current row</span>
<span class="s2">            int reward_array[</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">];</span>
<span class="s2">            for (size_t i = 0; i &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">            </span><span class="se">{{</span><span class="s2">&quot;&quot;&quot;</span><span class="p">)</span>

        <span class="c1"># generate code for reward vector based on dict in parameters</span>
        <span class="n">first_branch</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">rewards</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s2">&quot;elsewhere&quot;</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">branching</span> <span class="o">=</span> <span class="s2">&quot;else if&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">first_branch</span> <span class="k">else</span> <span class="s2">&quot;if&quot;</span>
            <span class="n">ppucode</span> <span class="o">+=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">indent</span><span class="p">(</span><span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                </span><span class="si">{</span><span class="n">branching</span><span class="si">}</span><span class="s2"> ((i == current_row - </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">) || (i == current_row + </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">))</span>
<span class="s2">                    reward_array[i] = </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">;&quot;&quot;&quot;</span><span class="p">),</span> <span class="s2">&quot;</span><span class="se">\t\t</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">first_branch</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">ppucode</span> <span class="o">+=</span> <span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                else</span>
<span class="s2">                    reward_array[i] = </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="s2">&quot;elsewhere&quot;</span><span class="p">]</span><span class="si">}</span><span class="s2">;</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            // read out spike counters</span>
<span class="s2">            size_t spike_counts[</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">];</span>
<span class="s2">            for (size_t i = 0; i &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                auto coord = halco::hicann_dls::vx::v3::AtomicNeuronOnDLS(</span>
<span class="s2">                    halco::hicann_dls::vx::v3::NeuronColumnOnDLS(i),</span>
<span class="s2">                    halco::hicann_dls::vx::v3::NeuronRowOnDLS()</span>
<span class="s2">                ).toSpikeCounterReadOnDLS();</span>
<span class="s2">                haldls::vx::v3::SpikeCounterRead container =</span>
<span class="s2">                    stadls::vx::v3::ppu::read&lt;</span>
<span class="s2">                    haldls::vx::v3::SpikeCounterRead&gt;(coord);</span>
<span class="s2">                spike_counts[i] = container.get_count();</span>
<span class="s2">                if (current_row &gt; 0)</span>
<span class="s2">                    all_spikes[i] += spike_counts[i];</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            // calculate reward and weight update rate</span>
<span class="s2">            int accumulator = 0;</span>
<span class="s2">            for (size_t i = 0; i &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">                accumulator += reward_array[i] * spike_counts[i];</span>
<span class="s2">            float reward = accumulator / 100.;</span>
<span class="s2">            float update_rate = (reward - mean_rewards[current_row])</span>
<span class="s2">                * </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">get_learning_rate</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="si">}</span><span class="s2">;</span>

<span class="s2">            // update weights</span>
<span class="s2">            for (size_t row = 0; row &lt; synapses[0].rows.size(); ++row) </span><span class="se">{{</span>
<span class="s2">                VectorRowMod8 weights = synapses[0].get_weights(row);</span>
<span class="s2">                VectorRowMod8 result;</span>
<span class="s2">                get_causal_correlation(&amp;result.even.data, &amp;result.odd.data, synapses[0].rows[row]);</span>

<span class="s2">                // shift result by 1 bit to stay in signed 8-bit int range</span>
<span class="s2">                VectorRowFracSat8 result_fracsat =</span>
<span class="s2">                    (result &gt;&gt; 1).convert_contiguous();</span>
<span class="s2">                VectorRowFracSat8 baselines_fracsat =</span>
<span class="s2">                    (correlation_baselines &gt;&gt; 1).convert_contiguous();</span>
<span class="s2">                VectorRowFracSat8 correlation_fracsat =</span>
<span class="s2">                    baselines_fracsat - result_fracsat;</span>

<span class="s2">                // multiplication of fracsat type scales down by 128 to</span>
<span class="s2">                // ensure we stay in value range, hence we multiply</span>
<span class="s2">                // the update_rate by 128</span>
<span class="s2">                VectorRowFracSat8 weight_update =</span>
<span class="s2">                    correlation_fracsat * static_cast&lt;int8_t&gt;(update_rate * 128);</span>

<span class="s2">                // truncate weight update, i.e. round symetrically to zero:</span>
<span class="s2">                // for negative updates, we want to add 1.</span>
<span class="s2">                weight_update = vector_if(</span>
<span class="s2">                    weight_update, VectorIfCondition::lesser,</span>
<span class="s2">                    weight_update + 1, weight_update);</span>
<span class="s2">                VectorRowFracSat8 new_weights =</span>
<span class="s2">                    static_cast&lt;VectorRowFracSat8&gt;(weights)</span>
<span class="s2">                    + weight_update;</span>

<span class="s2">                // clip weights to hardware range limits</span>
<span class="s2">                new_weights = check_boundaries(new_weights);</span>
<span class="s2">                weights = static_cast&lt;VectorRowMod8&gt;(new_weights);</span>

<span class="s2">                synapses[0].set_weights(weights, row);</span>
<span class="s2">            </span><span class="se">}}</span>

<span class="s2">            // update mean rewards</span>
<span class="s2">            mean_rewards[current_row] =</span>
<span class="s2">                (</span><span class="si">{</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">parameters</span><span class="o">.</span><span class="n">get_reward_decay</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="si">}</span><span class="s2"> * mean_rewards[current_row])</span>
<span class="s2">                + (</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">get_reward_decay</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span><span class="si">}</span><span class="s2"> * reward);</span>

<span class="s2">            // record mean reward:</span>
<span class="s2">            // The float value is casted to a char array to be passed to an</span>
<span class="s2">            // observable, since we have no float observables in PyNN yet.</span>
<span class="s2">            unsigned char array[4];</span>
<span class="s2">            *reinterpret_cast&lt;float*&gt;(array) = mean_rewards[current_row];</span>
<span class="s2">            for (size_t i = 0; i &lt; 4; ++i)</span>
<span class="s2">                recording.rewards[i] = array[i];</span>

<span class="s2">            // record success</span>
<span class="s2">            unsigned int paddle_position =</span>
<span class="s2">                std::max_element(&amp;spike_counts[0],</span>
<span class="s2">                                 &amp;spike_counts[</span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">])</span>
<span class="s2">                - &amp;spike_counts[0];</span>
<span class="s2">            if (reward_array[paddle_position] &gt;= 0)</span>
<span class="s2">                recording.success[0] = 1;</span>
<span class="s2">            else</span>
<span class="s2">                recording.success[0] = 0;</span>

<span class="s2">            // apply homeostasis at end of epoch</span>
<span class="s2">            if (current_row == </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">)</span>
<span class="s2">            </span><span class="se">{{</span>
<span class="s2">                VectorRowFracSat8 update(0);</span>

<span class="s2">                for (size_t column = 0; column &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++column)</span>
<span class="s2">                </span><span class="se">{{</span>
<span class="s2">                    int16_t deviation =</span>
<span class="s2">                        </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">homeostasis_target</span><span class="si">}</span><span class="s2"> - all_spikes[column];</span>
<span class="s2">                    update[column] =</span>
<span class="s2">                        deviation * </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">homeostasis_rate</span><span class="si">}</span><span class="s2">;</span>
<span class="s2">                </span><span class="se">}}</span>

<span class="s2">                for (size_t row = 0; row &lt; synapses[0].rows.size(); ++row) </span><span class="se">{{</span>
<span class="s2">                    VectorRowMod8 weights = synapses[0].get_weights(row);</span>
<span class="s2">                    VectorRowFracSat8 new_weights =</span>
<span class="s2">                        static_cast&lt;VectorRowFracSat8&gt;(weights) + update;</span>

<span class="s2">                    new_weights = check_boundaries(new_weights);</span>
<span class="s2">                    weights = static_cast&lt;VectorRowMod8&gt;(new_weights);</span>

<span class="s2">                    synapses[0].set_weights(weights, row);</span>
<span class="s2">                </span><span class="se">}}</span>

<span class="s2">                // reset row counter and spike accumulators</span>
<span class="s2">                current_row = 0;</span>
<span class="s2">                for (size_t i = 0; i &lt; </span><span class="si">{</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="si">}</span><span class="s2">; ++i)</span>
<span class="s2">                    all_spikes[i] = 0;</span>
<span class="s2">            </span><span class="se">}}</span>
<span class="s2">            else</span>
<span class="s2">                current_row++;</span>
<span class="s2">        </span><span class="se">}}</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ppucode</span>

<span class="c1"># create a timer that controls when this plasticity rule is executed</span>
<span class="n">plasticity_timer</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span>
    <span class="n">start</span><span class="o">=</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">input_duration</span> <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">init_duration</span>
           <span class="p">)</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
    <span class="n">period</span><span class="o">=</span><span class="n">parameters</span><span class="o">.</span><span class="n">row_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
    <span class="n">num_periods</span><span class="o">=</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)</span>

<span class="c1"># print returned PPU kernel code with c++ syntax highlighting</span>
<span class="k">class</span> <span class="nc">DemoRule</span><span class="p">(</span><span class="n">PlasticityRule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="n">ppu_code</span> <span class="o">=</span> <span class="n">DemoRule</span><span class="p">()</span><span class="o">.</span><span class="n">generate_kernel</span><span class="p">()</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">display_markdown</span><span class="p">(</span><span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">Markdown</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;``` c++ </span><span class="se">\n</span><span class="si">{</span><span class="n">ppu_code</span><span class="si">}</span><span class="se">\n</span><span class="s2">```&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>We will now create all necessary objects for PyNN to handle the
training.</p>
<p>More specifically, we…
* load a calibration for neurons and correlation sensors
* create populations and projections
* create input spiketrains handling multiple desired epochs in one run</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># download latest calibration</span>
<span class="n">save_nightly_calibration</span><span class="p">(</span>
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;correlation_calix-native.pkl&quot;</span><span class="p">,</span> <span class="n">source_folder</span><span class="o">=</span><span class="s2">&quot;latest-weekly&quot;</span><span class="p">)</span>

<span class="c1"># load calibration</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;correlation_calix-native.pkl&quot;</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">calibfile</span><span class="p">:</span>
    <span class="n">calib_result</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">calibfile</span><span class="p">)</span>

<span class="c1"># The correlation voltages are set on the board and therefore</span>
<span class="c1"># are not contained in lola.Chip(), so we inject them as a builder</span>
<span class="n">injected_config</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">InjectedConfiguration</span><span class="p">()</span>
<span class="n">calib_builder</span> <span class="o">=</span> <span class="n">sta</span><span class="o">.</span><span class="n">PlaybackProgramBuilder</span><span class="p">()</span>
<span class="n">calib_result</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">calib_builder</span><span class="p">)</span>
<span class="n">injected_config</span><span class="o">.</span><span class="n">pre_static_config</span> <span class="o">=</span> <span class="n">calib_builder</span>

<span class="n">calib_dumper</span> <span class="o">=</span> <span class="n">sta</span><span class="o">.</span><span class="n">PlaybackProgramBuilderDumper</span><span class="p">()</span>
<span class="n">calib_result</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">calib_dumper</span><span class="p">)</span>
<span class="n">calib_dumper</span> <span class="o">=</span> <span class="n">calib_dumper</span><span class="o">.</span><span class="n">done</span><span class="p">()</span>
<span class="n">calib</span> <span class="o">=</span> <span class="n">sta</span><span class="o">.</span><span class="n">convert_to_chip</span><span class="p">(</span><span class="n">calib_dumper</span><span class="p">,</span> <span class="n">lola</span><span class="o">.</span><span class="n">Chip</span><span class="p">())</span>

<span class="c1"># disable neuron readout to CADC (observe correlation instead)</span>
<span class="k">for</span> <span class="n">cadc_config</span> <span class="ow">in</span> <span class="n">calib</span><span class="o">.</span><span class="n">cadc_readout_chains</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">channels</span> <span class="ow">in</span> <span class="p">[</span><span class="n">cadc_config</span><span class="o">.</span><span class="n">channels_causal</span><span class="p">,</span>
                     <span class="n">cadc_config</span><span class="o">.</span><span class="n">channels_acausal</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">channel_config</span> <span class="ow">in</span> <span class="n">channels</span><span class="p">:</span>
            <span class="n">channel_config</span><span class="o">.</span><span class="n">enable_connect_neuron</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">injected_readout</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">InjectedReadout</span><span class="p">()</span>
<span class="n">injected_readout</span><span class="o">.</span><span class="n">post_realtime</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">halco</span><span class="o">.</span><span class="n">SynramOnDLS</span><span class="p">())</span>

<span class="n">pynn_config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;initial_config&quot;</span><span class="p">:</span> <span class="n">calib</span><span class="p">,</span>
               <span class="s2">&quot;injected_config&quot;</span><span class="p">:</span> <span class="n">injected_config</span><span class="p">,</span>
               <span class="s2">&quot;injected_readout&quot;</span><span class="p">:</span> <span class="n">injected_readout</span><span class="p">}</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate input spiketrains:</span>
<span class="c1"># spiketrain for noise row</span>
<span class="n">single_spiketrain_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
    <span class="n">parameters</span><span class="o">.</span><span class="n">init_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
    <span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">init_duration</span> <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">input_duration</span>
     <span class="p">)</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
    <span class="n">parameters</span><span class="o">.</span><span class="n">wait_between_noise</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">)</span>
<span class="n">spiketrains_noise</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span>
        <span class="n">single_spiketrain_noise</span>
        <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">row_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)])]</span>

<span class="c1"># spiketrain for each (target) input row</span>
<span class="n">spiketrains_per_input</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">input_row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">):</span>
    <span class="n">input_spikes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">wait_between_events</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">wait_between_events</span> \
                <span class="o">/</span> <span class="n">parameters</span><span class="o">.</span><span class="n">input_distribution</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">row</span> <span class="o">-</span> <span class="n">input_row</span><span class="p">)]</span>
            <span class="n">input_spikes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                <span class="mi">0</span><span class="p">,</span>
                <span class="n">parameters</span><span class="o">.</span><span class="n">input_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">,</span>
                <span class="n">wait_between_events</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="n">input_spikes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([]))</span>
    <span class="n">spiketrains_per_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_spikes</span><span class="p">)</span>

<span class="c1"># shift spiketrains to appropriate start time, concatenate them</span>
<span class="n">spiketrains_per_epoch</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">):</span>
    <span class="n">input_spikes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">spiketrains_per_input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">row</span><span class="p">]</span>
        <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">row_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span>
        <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">init_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">)]</span>
    <span class="n">spiketrains_per_epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">input_spikes</span><span class="p">))</span>

<span class="c1"># repeat spiketrains for multiple epochs</span>
<span class="n">spiketrains_multiple_epochs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">):</span>
    <span class="n">input_spikes</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">spiketrains_per_epoch</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
        <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epoch_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)]</span>
    <span class="n">spiketrains_multiple_epochs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">input_spikes</span><span class="p">))</span>
</pre></div>
</div>
<p>We’re now ready to start training. Executing the following cell will
train 100 epochs (default). This will take a few minutes. You can re-run
that cell (or select more epochs per cell execution) as long as you
desire and the training should yield better and better results. After
some 2000 epochs, the learned diagonal matrix will result in an (almost)
perfect pong game. But even after a few hundred epochs, you should be
able to observe an onset of the diagonal in the weights.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># select the number of epochs to train when executing the next cell:</span>
<span class="n">N_EPOCHS_TO_TRAIN</span> <span class="o">=</span> <span class="mi">100</span>
</pre></div>
</div>
<div class="test html-display-none highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_EPOCHS_TO_TRAIN</span> <span class="o">=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize PyNN</span>
<span class="n">pynn</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="o">**</span><span class="n">pynn_config</span><span class="p">)</span>

<span class="c1"># setup input and output populations and projections</span>
<span class="n">pop_output</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span>
    <span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">HXNeuron</span><span class="p">())</span>
<span class="n">pop_input</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span>
    <span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">SpikeSourceArray</span><span class="p">(</span><span class="n">spike_times</span><span class="o">=</span><span class="n">spiketrains_multiple_epochs</span><span class="p">))</span>
<span class="n">pop_noise</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">SpikeSourceArray</span><span class="p">(</span><span class="n">spike_times</span><span class="o">=</span><span class="n">spiketrains_noise</span><span class="p">))</span>

<span class="n">synapses</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">standardmodels</span><span class="o">.</span><span class="n">synapses</span><span class="o">.</span><span class="n">PlasticSynapse</span><span class="p">(</span>
    <span class="n">plasticity_rule</span><span class="o">=</span><span class="n">PlasticityRule</span><span class="p">(</span><span class="n">timer</span><span class="o">=</span><span class="n">plasticity_timer</span><span class="p">,</span> <span class="n">same_id</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">weight</span><span class="o">=</span><span class="n">logical_weights</span> <span class="k">if</span> <span class="n">logical_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))</span>
<span class="n">projection</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Projection</span><span class="p">(</span>
    <span class="n">pop_input</span><span class="p">,</span> <span class="n">pop_output</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">AllToAllConnector</span><span class="p">(),</span>
    <span class="n">synapse_type</span><span class="o">=</span><span class="n">synapses</span><span class="p">,</span> <span class="n">receptor_type</span><span class="o">=</span><span class="s2">&quot;excitatory&quot;</span><span class="p">)</span>

<span class="n">synapses_noise</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">standardmodels</span><span class="o">.</span><span class="n">synapses</span><span class="o">.</span><span class="n">PlasticSynapse</span><span class="p">(</span>
    <span class="n">plasticity_rule</span><span class="o">=</span><span class="n">NoiseSynapseRule</span><span class="p">(</span><span class="n">timer</span><span class="o">=</span><span class="n">init_timer</span><span class="p">,</span> <span class="n">same_id</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">weight</span><span class="o">=</span><span class="mi">63</span><span class="p">)</span>
<span class="n">projection_noise</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Projection</span><span class="p">(</span>
    <span class="n">pop_noise</span><span class="p">,</span> <span class="n">pop_output</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">AllToAllConnector</span><span class="p">(),</span>
    <span class="n">synapse_type</span><span class="o">=</span><span class="n">synapses_noise</span><span class="p">,</span> <span class="n">receptor_type</span><span class="o">=</span><span class="s2">&quot;excitatory&quot;</span><span class="p">)</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_EPOCHS_TO_TRAIN</span> <span class="o">//</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">):</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">n_epochs_trained</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;=</span> <span class="n">parameters</span><span class="o">.</span><span class="n">noise_range_epochs</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training finished!&quot;</span><span class="p">)</span>
        <span class="n">plot_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">generate_plot</span><span class="p">(</span><span class="n">logical_weights</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">output</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">update_plot</span><span class="p">(</span><span class="n">plot_data</span><span class="p">,</span> <span class="n">logical_weights</span><span class="p">)</span>
        <span class="k">break</span>

    <span class="n">pynn</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">epoch_duration</span><span class="o">.</span><span class="n">rescale</span><span class="p">(</span><span class="n">pq</span><span class="o">.</span><span class="n">ms</span><span class="p">)</span><span class="o">.</span><span class="n">magnitude</span>
             <span class="o">*</span> <span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">)</span>

    <span class="c1"># look up routing:</span>
    <span class="c1"># The order of placed input rows on chip differs from the logical</span>
    <span class="c1"># order of inputs. When looking at the weights read back from</span>
    <span class="c1"># hardware, we need to adjust to the order of placed connections.</span>
    <span class="c1"># We fill the array `routing` to contain the placed coordinate</span>
    <span class="c1"># for each logical connection, based on the data from PyNN.</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">connections</span> <span class="o">=</span> <span class="n">projection</span><span class="o">.</span><span class="n">connections</span>
        <span class="n">placed_connections</span> <span class="o">=</span> <span class="n">projection</span><span class="o">.</span><span class="n">placed_connections</span>
        <span class="n">routing</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
            <span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">parameters</span><span class="o">.</span><span class="n">n_outputs</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">connections</span><span class="p">):</span>
            <span class="n">routing</span><span class="p">[</span><span class="n">connections</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">pop_pre_index</span><span class="p">,</span>
                    <span class="n">connections</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">pop_post_index</span><span class="p">]</span> <span class="o">=</span> \
                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">placed_connections</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">synapse_row</span><span class="p">,</span>
                          <span class="n">placed_connections</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">synapse_on_row</span><span class="p">])</span>

    <span class="n">post_realtime_reads</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">get_post_realtime_read</span><span class="p">()</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">post_realtime_reads</span><span class="p">[</span><span class="n">halco</span><span class="o">.</span><span class="n">SynramOnDLS</span><span class="p">()]</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">run_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">epochs_per_run</span><span class="p">):</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">)</span>
        <span class="n">success</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span><span class="p">):</span>
            <span class="c1"># extract rewards and success from recording</span>
            <span class="n">data_index</span> <span class="o">=</span> <span class="n">row</span> <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">n_inputs</span> <span class="o">*</span> <span class="n">run_epoch</span>
            <span class="n">success</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">synapses</span><span class="o">.</span><span class="n">plasticity_rule</span><span class="o">.</span><span class="n">get_observable_array</span><span class="p">(</span>
                <span class="s2">&quot;success&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="n">data_index</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># The reward was saved as a char array and needs to be</span>
            <span class="c1"># converted back to a float:</span>
            <span class="n">raw_data</span> <span class="o">=</span> <span class="n">synapses</span><span class="o">.</span><span class="n">plasticity_rule</span><span class="o">.</span><span class="n">get_observable_array</span><span class="p">(</span>
                <span class="s2">&quot;rewards&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="n">data_index</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
            <span class="n">packed_data</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="s2">&quot;4B&quot;</span><span class="p">,</span> <span class="o">*</span><span class="n">raw_data</span><span class="p">[:</span><span class="mi">4</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">rewards</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">=</span> <span class="n">struct</span><span class="o">.</span><span class="n">unpack</span><span class="p">(</span><span class="s2">&quot;f&quot;</span><span class="p">,</span> <span class="n">packed_data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">data</span><span class="o">.</span><span class="n">reward_archive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
        <span class="n">data</span><span class="o">.</span><span class="n">success_archive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">success</span><span class="p">)</span>

    <span class="n">logical_weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">routing</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">routing</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]]</span>
    <span class="n">data</span><span class="o">.</span><span class="n">mean_diagonal_weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logical_weights</span><span class="p">[</span><span class="n">parameters</span><span class="o">.</span><span class="n">diagonal_entries</span><span class="p">()]))</span>
    <span class="n">data</span><span class="o">.</span><span class="n">mean_off_diagonal_weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logical_weights</span><span class="p">[</span><span class="n">parameters</span><span class="o">.</span><span class="n">off_diagonal_entries</span><span class="p">()]))</span>

    <span class="n">projection</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">logical_weights</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">epoch_id</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
            <span class="n">plot_data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">generate_plot</span><span class="p">(</span><span class="n">logical_weights</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">output</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">update_plot</span><span class="p">(</span><span class="n">plot_data</span><span class="p">,</span> <span class="n">logical_weights</span><span class="p">)</span>

    <span class="n">pynn</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="n">pynn</span><span class="o">.</span><span class="n">end</span><span class="p">()</span>
</pre></div>
</div>
<p>In the plot above, a diagonal matrix should be visible after rougly a
hundred epochs of training. Also, the success (red), indicating the
performance of the network in the Pong game, should start to increase
slightly.</p>
<p>Now that the network has trained a bit, we can use the trained weights
for an actual game of pong. The left player is controlled by an ideal
weight matrix on a second set of hardware neurons, while the right
player uses the weights trained above. To keep the animation fluent, the
game is run in advance and animated only later, in a separate cell, so
you can replay the same game multiple times.</p>
<p>The performance of the agent on the right may be better than the
accuracy reported above, since we don’t add any noise here - but need
the noise during traing to enable exploration. Still, after 100 epochs,
the right player will lose the game rather quickly, and after some 300
epochs, it will play for quite some time, possibly reaching the end of
the pre-computed game (where we report the game ended in a tie).</p>
<p>You can switch between training and animation as you like.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize a new pong game - this clears the scores!</span>
<span class="n">pong_game</span> <span class="o">=</span> <span class="n">PongGame</span><span class="p">(</span>
    <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">pynn_config</span><span class="o">=</span><span class="n">pynn_config</span><span class="p">,</span>
    <span class="n">spiketrains_per_input</span><span class="o">=</span><span class="n">spiketrains_per_input</span><span class="p">)</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/pong_training_100epochs.png"><img alt="Pong performance after 100 epochs" class="solution align-center" src="../_images/pong_training_100epochs.png" style="width: 700px;" /></a>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># run a pong game using the weights trained above. This takes a few seconds since we run it on chip.</span>
<span class="n">pong_game</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">learned_weights</span><span class="o">=</span><span class="n">logical_weights</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display the animation of the game - re-executing will replay the same game.</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pong_game</span><span class="o">.</span><span class="n">spiketrains_per_input</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s2">&quot;In order to run the game on chip, please run the two cells above!&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">pong_game</span><span class="o">.</span><span class="n">animate</span><span class="p">()</span>
</pre></div>
</div>
<p>Finally, we want to show you that this setup is capable of training even
a larger matrix with smaller paddles - a more difficult task than with the
default parameters above. Here, we need to train longer, and training for
about 1000 epochs takes around an hour - hence we provide a plot of that here.
But feel free to tweak a few of the parameters (defined at the start of
the notebook), and continue training the network after the tutorial!
This plot was generated using the unmodified
<code class="docutils literal notranslate"><span class="pre">parameters</span> <span class="pre">=</span> <span class="pre">Parameters()</span></code>, i.e. without the adjustments in the
default notebook.</p>
<a class="reference internal image-reference" href="../_images/pong_training_996epochs.png"><img alt="Pong performance after 1000 epochs" class="align-center" src="../_images/pong_training_996epochs.png" style="width: 729px;" /></a>
</div>
<div class="section" id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Permalink to this headline"></a></h2>
<p>The notebook was developed in the Electronic Vision(s) group in 2023.
The main author is Johannes Weis.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ts_06-dynamic_range.html" class="btn btn-neutral float-left" title="Exploring the dynamic range" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ts_08-adex_complex_dynamics.html" class="btn btn-neutral float-right" title="Complex Neuron Dynamics with a Silicon Adaptive Exponential Integrate-and-Fire Neuron" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Electronic Vision(s).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>