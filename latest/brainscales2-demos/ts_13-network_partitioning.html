<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Partitioning of Feedforward SNNs &mdash; BrainScaleS-2 Documentation 0.0.1 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/visions.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction to matrix multiplication" href="tp_00-introduction.html" />
    <link rel="prev" title="hxtorch.snn Introduction" href="ts_12-hxtorch_snn_intro.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            BrainScaleS-2 Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Demos &amp; Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="tutorial.html">Demos and Examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="ts_00-single_neuron.html">BrainScaleS-2 single neuron experiments</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_01-superspike.html">Learning with the SuperSpike rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_02-plasticity_rate_coding.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_03-multicompartment.html">Multicompartmental Neurons</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_04-mc_genetic_algorithms.html">How to use Genetic Algorithms to automatically parameterize BrainScaleS-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_05-yin_yang.html">Training an SNN on BrainScaleS-2 with PyTorch</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_06-dynamic_range.html">Exploring the dynamic range</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_07-pong.html">Pong</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_08-adex_complex_dynamics.html">Complex Neuron Dynamics with a Silicon Adaptive Exponential Integrate-and-Fire Neuron</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_09-inside_realtime_hook.html">Demonstration of inside realtime hook</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_10-multiple_configs.html">Demonstration of multiple chip-reconfigurations during an experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_11-plasticity_homeostasis.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="ts_12-hxtorch_snn_intro.html">hxtorch.snn Introduction</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Partitioning of Feedforward SNNs</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#references-and-further-reading">References and further reading</a></li>
<li class="toctree-l4"><a class="reference internal" href="#encoding">Encoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decoding">Decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-model">The Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#calibrations-and-parameters">Calibrations and Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-and-testing">Training and Testing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#final-setup-and-the-training-loop">Final Setup And The Training Loop</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-training-loop">The Training Loop</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tp_00-introduction.html">Introduction to matrix multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="tp_01-properties.html">Exploring the analog MAC operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="tp_02-yin_yang.html">Train DNNs on BrainScaleS-2</a></li>
<li class="toctree-l3"><a class="reference internal" href="nmpi_00-non_interactive_queue_runner.html">Introduction to the non-interactive queue runner</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#executing-the-notebooks">Executing the Notebooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#shared-hardware-resources">Shared Hardware Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial.html#final-test-hardware-execution">Final test: Hardware Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="girlsday.html">Wie verarbeitet unser Gehirn Informationen?</a></li>
<li class="toctree-l2"><a class="reference internal" href="fortgeschrittenen_praktikum.html">Welcome to the Advanced Physics Lab for Physicists by the Electronic Vision(s) Group</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../software_components.html">Software Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">BrainScaleS-2 Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Welcome to the BrainScaleS-2 Demos &amp; Examples!</a></li>
          <li class="breadcrumb-item"><a href="tutorial.html">Welcome to the BrainScaleS-2 Tutorial</a></li>
      <li class="breadcrumb-item active">Partitioning of Feedforward SNNs</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/brainscales2-demos/ts_13-network_partitioning.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="partitioning-of-feedforward-snns">
<h1>Partitioning of Feedforward SNNs<a class="headerlink" href="#partitioning-of-feedforward-snns" title="Permalink to this headline"></a></h1>
<p>In this tutorial we will discuss network partitioning for feedforward networks on BrainScaleS-2 (BSS-2) [1].
We will create a spiking neural network (SNN) in <code class="docutils literal notranslate"><span class="pre">hxtorch.snn</span></code> [2] based on the output of a partitioning algorithm and train it with BSS-2 in-the-loop with the surrogate gradient (SG) method [3] to solve the MNIST [4] task.
This experiment has been published in [5].</p>
<p>If you are not familiar with <code class="docutils literal notranslate"><span class="pre">hxtorch.snn</span></code> or the BSS-2 system, you might want to do previous tutorials first or take a look at the following references.
This tutorial will not detail their corresponding working principles.</p>
<div class="section" id="references-and-further-reading">
<h2>References and further reading<a class="headerlink" href="#references-and-further-reading" title="Permalink to this headline"></a></h2>
<p>[1] Pehle, C., Billaudelle, S., Cramer, B., Kaiser, J., Schreiber, K.,
Stradmann, Y., Weis, J., Leibfried, A., Müller, E., and Schemmel, J. The
BrainScaleS-2 accelerated neuromorphic system with hybrid plasticity.
Frontiers in Neuroscience, 16, 2022. ISSN 1662-453X. <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2022.795876/full">doi:
10.3389/fnins.2022.795876</a></p>
<p>[2] Spilger, P., Arnold, E., Blessing, L., Mauch, C., Pehle, C., Müller,
E., and Schemmel, J. hxtorch.snn: Machine- learning-inspired spiking
neural network modeling on BrainScaleS-2. 2023. <a class="reference external" href="https://doi.org/10.48550/arXiv.2212.12210">doi:
10.48550.2212.12210</a></p>
<p>[3] Emre O. Neftci, Hesham Mostafa, and Friedemann Zenke. 2019.
Surrogate gradi- ent learning in spiking neural networks: Bringing the
power of gradient-based optimization to spiking neural networks. IEEE
Signal Processing Magazine 36, 6 (2019),51–63.
<a class="reference external" href="https://doi.org/10.1109/MSP.2019.2931595">https://doi.org/10.1109/MSP.2019.2931595</a></p>
<p>[4] Yann LeCun and Corinna Cortes. The MNIST database of handwritten
digits. 1998.</p>
<p>[5] Arnold, E., Spilger, P., Straub, J. V., Müller, E., Dold, D., Meoni,
G., Schemmel, J. Scalable Network Emulation on Analog Neuromorphic
Hardware. Frontiers in Neuroscience. 2025. <a class="reference external" href="https://doi.org/10.3389/fnins.2024.1523331">doi:
10.3389/fnins.2024.1523331</a></p>
<div class="section" id="a-partitioning-algorithm">
<h3>A Partitioning Algorithm<a class="headerlink" href="#a-partitioning-algorithm" title="Permalink to this headline"></a></h3>
<p>When working with feedforward neural networks, the typical network structure that arises will look like this:</p>
<a class="reference internal image-reference" href="../_images/feedforward-network.jpeg"><img alt="../_images/feedforward-network.jpeg" class="align-center" src="../_images/feedforward-network.jpeg" style="width: 60%;" /></a>
<p>The marked regions represent layers of the network and the dots the neurons within them.
We will work with an input layer, some hidden layers and an output layer with dense synaptic connections between the neurons of consecutive layers.</p>
<p>The BSS-2 System consists of 512 AdEx-neuron circuits with a fan-in of 256 individual synaptic connections to each of them.
The weights of these synaptic connections can be either excitatory (positive) or inhibitory (negative) and can in each case be configured within 6 bit (inhibitory: <span class="math notranslate nohighlight">\([-63, ..., 0]\)</span>, excitatory: <span class="math notranslate nohighlight">\([0, ..., 63]\)</span>).
To work with signed weights, we can combine two synaptic rows, one for each input type.
This, in return, reduces the fan-in per neuron circuit to 128.
A higher fan-in can be achieved by connecting neuron circuits on BSS-2 such that they share their membrane voltage and add their respective fan-in.
This decreases the number of available neurons on chip.</p>
<p>Networks requiring more neuron resources than the chip provides, need to be partitioned into subnetworks, each fitting on a single BSS-2 instance.
As the neurons of any given layer are not interconnected and the information is propagated through the network in one direction only (feedforward), a postsynaptic layer can be split into multiple independent sublayers, each receiving all inputs from the presynaptic layer (in case of dense connections in between).
Making use of this characteristic, we can turn this into a multi-step-process and run all the sublayers consecutively on the current single-chip BSS-2 hardware
In the future, all parts are run in parallel on multi-chip hardware.
After all the runs in a particular layer, we can combine their outputs and can move on to the next layer and then repeat the partitioning process
The following image showcases this procedure:</p>
<a class="reference internal image-reference" href="../_images/feedforward-partitioning_idea.jpeg"><img alt="../_images/feedforward-partitioning_idea.jpeg" class="align-center" src="../_images/feedforward-partitioning_idea.jpeg" style="width: 60%;" /></a>
<p>We will now try to find an optimal partition for a given network.
Let’s say it consists of <span class="math notranslate nohighlight">\(L \in\mathbb{N}\)</span> layers with <span class="math notranslate nohighlight">\(N_l \in\mathbb{N}\)</span> neurons in layer <span class="math notranslate nohighlight">\(l \leq L\)</span>.
For the fully connected structure, every neuron in a following layer will have to be provided with a fan-in of the number of neurons in the previous layer (<span class="math notranslate nohighlight">\(N_{ l-1 }\)</span>).
We can calculate how many neurons circuits <span class="math notranslate nohighlight">\(c_l\)</span> have to be connected in order to achieve this fan-in:</p>
<div class="math notranslate nohighlight">
\[c_l = \left\lceil \frac{N_{l-1}}{128}\right\rceil.\]</div>
<p>In the next step, we want to know how many neurons of this size fit on one chip:</p>
<div class="math notranslate nohighlight">
\[N^\text{BSS-2}_l = N(c_l) = \left\lfloor \frac{512}{c_l}\right\rfloor.\]</div>
<p>Last but not least, this implies the number of necessary partitions for a given layer:</p>
<div class="math notranslate nohighlight">
\[p_l = \left\lceil\frac{N_l}{N(c_l)} \right\rceil.\]</div>
<p>We can calculate this for each layer <span class="math notranslate nohighlight">\(l\)</span>.
If several consecutive layers do not need to be partitioned  (<span class="math notranslate nohighlight">\(p_l = p_{l+1} = … = p_{l+n} = 1\)</span>), we can also check if these parts of the network can be executed in one hardware run, i.e. fit on the chip together.</p>
</div>
<div class="section" id="example-with-the-mnist-data-set">
<h3>Example with the MNIST data set<a class="headerlink" href="#example-with-the-mnist-data-set" title="Permalink to this headline"></a></h3>
<p>We are now going to implement an SNN in <code class="docutils literal notranslate"><span class="pre">hxtorch.snn</span></code> and put it to the test by training the resulting network on BSS-2.
Before we can actually train a network, a few more steps have to be considered.</p>
<p>In this example we will make use of the MNIST data set [4].
It contains <span class="math notranslate nohighlight">\(28 \times 28\)</span> gray scale images of the numbers from zero up to nine.
The goal of our trained network will be to classify these images correctly.
To do that, lets set the input space of the network to the image size: <span class="math notranslate nohighlight">\(28 \times 28 = 784\)</span> and use a hidden layer consisting of 256 leaky-integrate-and-fire (LIF) neurons.
The 10 leaky integrators in our output layer correspond to the ten classes of the data set.
For this network architecture, partitioning results in 5 subnetworks.
The input space of <span class="math notranslate nohighlight">\(784\)</span> neurons requires connecting 7 neuron circuits; for convenience, we use 8, which simplifies the mapping process.
This configuration reduces the number of “logical” neurons per BSS-2 chip to 64, so the hidden layer is divided into 4 partitions.
In the output layer, 2 neuron circuits are connected, allowing the entire layer to be executed on a single BSS-2 instance.</p>
<p>Let’s load the data set before we continue with the encoding:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up hardware client</span>
<span class="kn">from</span> <span class="nn">_static.common.helpers</span> <span class="kn">import</span> <span class="n">setup_hardware_client</span>
<span class="n">setup_hardware_client</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">_static.tutorial.partitioning_helpers</span> <span class="kn">import</span> <span class="n">RandomRandomRotation</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">dataset_size</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">dev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;device:&quot;</span><span class="p">,</span> <span class="n">dev</span><span class="p">)</span>
</pre></div>
</div>
<div class="test html-display-none highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset_size</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define the rotation that is applied</span>
<span class="n">RotationTransform</span> <span class="o">=</span> <span class="n">RandomRandomRotation</span><span class="p">(</span><span class="n">dmin</span><span class="o">=-</span><span class="mi">25</span><span class="p">,</span> <span class="n">dmax</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">prob</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">transform_train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">RotationTransform</span><span class="p">])</span>
<span class="n">transform_test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>

<span class="c1"># We either use existing MNIST dataset or download into &quot;./mnist&quot;</span>
<span class="n">dataset_location</span> <span class="o">=</span> <span class="s2">&quot;/loh/data/mnist&quot;</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;/loh/data/mnist&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;./mnist&quot;</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dataset_location</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform_train</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="n">dataset_location</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform_test</span><span class="p">)</span>

<span class="c1"># We only train on 10% of the data to increase execution speed</span>
<span class="c1"># ... comment this out if you want to train on the whole dataset</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span><span class="p">(</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">dataset_size</span><span class="p">)))</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Subset</span><span class="p">(</span>
    <span class="n">test_data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span> <span class="o">*</span> <span class="n">dataset_size</span><span class="p">)))</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
<p>As you can see, we can augment the data set by applying random rotations to some of the data to counteract overfitting.
The probability with which these are applied and the angle range can be specified here.</p>
</div>
</div>
<div class="section" id="encoding">
<h2>Encoding<a class="headerlink" href="#encoding" title="Permalink to this headline"></a></h2>
<p>We have to encode the real valued input data into spike trains in order for the LIF neurons to be able to work with it.
An efficient encoding approach is a time-to-first-spike (TTFS) encoding where each pixel is translated to single spike event.
We will implement it a linear manner:</p>
<p>As hxtorch computes gradients by representing the network dynamics on a discrete time grid of length <span class="math notranslate nohighlight">\(T\)</span> time steps, each value of each pixel will be mapped to a discrete time-index <span class="math notranslate nohighlight">\(t_{\text{idx}} \in\mathbb{N}\)</span> along a spike train of length <span class="math notranslate nohighlight">\(T \in\mathbb{N}\)</span> at which a spike will be placed.</p>
<div class="math notranslate nohighlight">
\[x \mapsto T\cdot \frac{x-x_{\text{min}}}{x_{\text{max}}- x_{\text{min}}} =: t_1, \quad
t_1 \mapsto T - \left\lfloor{t}_1\right\rceil =: t_{\text{idx}},\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{\text{ min/max }}\)</span> is the minimum/maximum value of the data set.
The mixed flooring and ceiling brackets indicate rounding to the next integer.
With an encoding like this, high values are represented by early spikes and (while decreasing linearly) values close to <span class="math notranslate nohighlight">\(x_{\text{min}}\)</span> result in spike times near to <span class="math notranslate nohighlight">\(T\)</span>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ttfs_encode</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">x_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
                <span class="n">x_max</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Translate the image into a time-to-first-spike representation.</span>

<span class="sd">    :param x: The image to encode into spikes.</span>
<span class="sd">    :param sequence_length: The length of time sequence, i.e. number of time steps.</span>
<span class="sd">    :param x_min: The minimum pixel value to still resulting in a spike.</span>
<span class="sd">    :param x_max: The pixel value for which (and above) the spike time is at time step 0.</span>
<span class="sd">    :return: The spiking representation of the image.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">indx</span> <span class="o">=</span> <span class="n">sequence_length</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span>
        <span class="p">(</span><span class="n">sequence_length</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">))</span>
    <span class="n">x_enc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">sequence_length</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">):</span>
        <span class="n">x_enc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">indx</span> <span class="o">==</span> <span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x_enc</span>
</pre></div>
</div>
<p>The full pre-processing of an image is shown in the following figure:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">_static.tutorial.partitioning_plots</span> <span class="kn">import</span> <span class="n">show_transforms</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">show_transforms</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">RotationTransform</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">ttfs_encode</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">30</span><span class="p">))</span>
</pre></div>
</div>
<p>Note that the image in the middle might be the same as the initial image, depending on the probability of the application given to <code class="docutils literal notranslate"><span class="pre">RandomRandomRotation(...,</span> <span class="pre">...,</span> <span class="pre">prob=...)</span></code>.</p>
</div>
<div class="section" id="decoding">
<h2>Decoding<a class="headerlink" href="#decoding" title="Permalink to this headline"></a></h2>
<p>As we chose leaky integrators in the last layer of the network, there will be no spiking behavior in this output layer.
We will have to apply some kind of decoding to the membrane traces that are being recorded on BSS-2 to turn them into class scores in order to infer a prediction.
A simple method to achieve this is a max-over-time decoding: the maximum value of each membrane trace will used to derive a probability for each class label.
For that we use the log-softmax function in conjunction with <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code>’s <code class="docutils literal notranslate"><span class="pre">torch.nn.functional.nll_loss</span></code>, which corresponds to the Cross Entropy Loss.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">trace_scaling</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decode the output membrane traces into class scores.</span>

<span class="sd">    :param x: Membrane traces from the output layer.</span>
<span class="sd">    :param trace_scaling: Scaling factor for the traces.</span>
<span class="sd">    :return: Log-probabilities for each class.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">amax</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">trace_scaling</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">log_p_y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_p_y</span>
</pre></div>
</div>
</div>
<div class="section" id="the-model">
<h2>The Model<a class="headerlink" href="#the-model" title="Permalink to this headline"></a></h2>
<p>The class <code class="docutils literal notranslate"><span class="pre">SNN</span></code> creates a model in a similar fashion to the known <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code> formulation.
It defines the projections and neuron layers of the network.
In the <code class="docutils literal notranslate"><span class="pre">forward</span></code>-method, an input is traversed through the network and the respective output is returned.</p>
<p>The class <code class="docutils literal notranslate"><span class="pre">Model</span></code> puts together what we already have and creates a complete model with encoder, network and decoder.
It even consists of a regularization method that might come in handy later on.
When creating the synapses, the parameter <code class="docutils literal notranslate"><span class="pre">transforms</span></code> allows us to apply a function to the weights before they are used in the networks calculations.
To ensure compatibility with the physical constraints of BSS-2, we apply a weight saturation function that limits weights to the hardware boundaries.
Additionally, in the Synapse module’s numerical implementation (see <code class="docutils literal notranslate"><span class="pre">forward_func</span></code>), we use a clamping function with exponential decay near the extreme values (<span class="math notranslate nohighlight">\(-63\)</span> and <span class="math notranslate nohighlight">\(63\)</span>).
This approach prevents weight over-saturation and helps maintain consistency between software and hardware weights.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">hxtorch</span>
<span class="kn">import</span> <span class="nn">hxtorch.spiking</span> <span class="k">as</span> <span class="nn">hxsnn</span>
<span class="kn">import</span> <span class="nn">hxtorch.spiking.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">hxtorch.spiking.transforms</span> <span class="kn">import</span> <span class="n">weight_transforms</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Synapse</span><span class="p">(</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">Synapse</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">cap</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">weight_exp_rolloff</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                <span class="n">use_quantization</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the Synapse.</span>

<span class="sd">        :param use_quantization: Whether to use quantized weights in the numerical</span>
<span class="sd">            forwardpass.</span>
<span class="sd">        :param cap: Maximum allowed weight value for the model weights (saturation cap).</span>
<span class="sd">        :param weight_exp_rolloff: Start of exponential rolloff for weights towards</span>
<span class="sd">            saturation cap.</span>
<span class="sd">        :param args: Additional positional arguments for parent class.</span>
<span class="sd">        :param kwargs: Additional keyword arguments for parent class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cap</span> <span class="o">=</span> <span class="n">cap</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_exp_rolloff</span> <span class="o">=</span> <span class="n">weight_exp_rolloff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_quantization</span> <span class="o">=</span> <span class="n">use_quantization</span>

    <span class="k">def</span> <span class="nf">forward_func</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">LIFObservables</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">SynapseHandle</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">SynapseHandle</span><span class="p">(</span>
            <span class="n">graded_spikes</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">linear_exponential_clamp</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">.</span><span class="n">spikes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">cap</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cap</span><span class="p">,</span> <span class="n">start_weight</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_exp_rolloff</span><span class="p">,</span>
                <span class="n">quantize</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_quantization</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">SNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SNN consiting of a hidden LIF layer and subseqent LI output layer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">lif_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
            <span class="n">li_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
            <span class="n">mock</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">dt</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0e-6</span><span class="p">,</span>
            <span class="n">use_quantization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">trace_shift_hidden</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">trace_shift_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">weight_init_hidden</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">weight_init_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">weight_scale_hidden</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
            <span class="n">weight_scale_output</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
            <span class="n">trace_scale_hidden</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
            <span class="n">trace_scale_output</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
            <span class="n">weight_exp_rolloff</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
            <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the SNN.</span>

<span class="sd">        :param lif_params: Params for LIF neurons. Also used for calibration.</span>
<span class="sd">        :param li_params: Params for LI neurons. Also used for calibration.</span>
<span class="sd">        :param mock: Indicating whether to train in software or on</span>
<span class="sd">        :param dt: Time-binning width.</span>
<span class="sd">        :param use_quantization: Wether to use discrete weights in</span>
<span class="sd">            simulation forward.</span>
<span class="sd">        :param weight_init_hidden: Weight initialization mean</span>
<span class="sd">            and standard deviation.</span>
<span class="sd">        :param weight_init_output: Output layer weight initialization mean</span>
<span class="sd">            and standard deviation.</span>
<span class="sd">        :param weight_scale_hidden: The factor with which the hidden</span>
<span class="sd">            software weights are scaled when mapped to hardware.</span>
<span class="sd">        :param weight_scale_output: The factor with which the output</span>
<span class="sd">            software weights are scaled when mapped to hardware.</span>
<span class="sd">        :param trace_scale_hidden: The factor with which the membrane</span>
<span class="sd">            traces of the hidden neurons are scaled when mapped from</span>
<span class="sd">            hardware measurements to software.</span>
<span class="sd">        :param trace_scale_output: The factor with which the membrane</span>
<span class="sd">            traces of the readout neurons are scaled when mapped from</span>
<span class="sd">            hardware measurements to software.</span>
<span class="sd">        :param weight_exp_rolloff: Weights with higher absolutes are rolled off</span>
<span class="sd">            exponentially in software.</span>
<span class="sd">        :param device: The used PyTorch device used for tensor operations</span>
<span class="sd">            in software.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">exp</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">Experiment</span><span class="p">(</span><span class="n">mock</span><span class="o">=</span><span class="n">mock</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="o">.</span><span class="n">inter_batch_entry_wait</span> <span class="o">=</span> <span class="mi">125</span> <span class="o">*</span> <span class="mi">50</span>  <span class="c1"># 50 us</span>

        <span class="n">morph_hidden</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">expand_horizontally</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Hidden Layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">256</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden</span><span class="p">,</span> <span class="n">neurons_hidden</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">inst</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">ExecutionInstance</span><span class="p">()</span>
            <span class="n">linear</span> <span class="o">=</span> <span class="n">Synapse</span><span class="p">(</span>
                <span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span>
                <span class="n">out_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="n">experiment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span>
                <span class="n">execution_instance</span><span class="o">=</span><span class="n">inst</span><span class="p">,</span>
                <span class="n">cap</span><span class="o">=</span><span class="mf">1.</span> <span class="k">if</span> <span class="n">mock</span> <span class="k">else</span> <span class="mf">63.</span> <span class="o">/</span> <span class="n">weight_scale_hidden</span><span class="p">,</span>
                <span class="n">weight_exp_rolloff</span><span class="o">=</span><span class="n">weight_exp_rolloff</span><span class="p">,</span>
                <span class="n">use_quantization</span><span class="o">=</span><span class="n">use_quantization</span><span class="p">,</span>
                <span class="n">transform</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                    <span class="n">weight_transforms</span><span class="o">.</span><span class="n">linear_saturating</span><span class="p">,</span>
                    <span class="n">scale</span><span class="o">=</span><span class="n">weight_scale_hidden</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;linear_hidden_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>

            <span class="n">neuron</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">LIF</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="o">**</span><span class="n">lif_params</span><span class="p">,</span>
                <span class="n">experiment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span>
                <span class="n">execution_instance</span><span class="o">=</span><span class="n">inst</span><span class="p">,</span>
                <span class="n">trace_scale</span><span class="o">=</span><span class="n">trace_scale_hidden</span><span class="p">,</span>
                <span class="n">cadc_time_shift</span><span class="o">=</span><span class="n">trace_shift_hidden</span><span class="p">,</span>
                <span class="n">shift_cadc_to_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">neuron_structure</span><span class="o">=</span><span class="n">morph_hidden</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;neuron_hidden_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">neuron</span><span class="p">)</span>
            <span class="n">neurons_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span>

        <span class="c1"># Output Layer</span>
        <span class="n">morph_out</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expand_horizontally</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

        <span class="n">inst</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">ExecutionInstance</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
            <span class="n">linear</span> <span class="o">=</span> <span class="n">Synapse</span><span class="p">(</span>
                <span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
                <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">execution_instance</span><span class="o">=</span><span class="n">inst</span><span class="p">,</span>
                <span class="n">experiment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span>
                <span class="n">cap</span><span class="o">=</span><span class="mf">1.</span> <span class="k">if</span> <span class="n">mock</span> <span class="k">else</span> <span class="mf">63.</span> <span class="o">/</span> <span class="n">weight_scale_output</span><span class="p">,</span>
                <span class="n">weight_exp_rolloff</span><span class="o">=</span><span class="n">weight_exp_rolloff</span><span class="p">,</span>
                <span class="n">use_quantization</span><span class="o">=</span><span class="n">use_quantization</span><span class="p">,</span>
                <span class="n">transform</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span>
                    <span class="n">weight_transforms</span><span class="o">.</span><span class="n">linear_saturating</span><span class="p">,</span>
                    <span class="n">scale</span><span class="o">=</span><span class="n">weight_scale_output</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">linear_output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;linear_output_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">neuron_output</span> <span class="o">=</span> <span class="n">hxsnn</span><span class="o">.</span><span class="n">LI</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="o">**</span><span class="n">li_params</span><span class="p">,</span>
            <span class="n">experiment</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span>
            <span class="n">execution_instance</span><span class="o">=</span><span class="n">inst</span><span class="p">,</span>
            <span class="n">trace_scale</span><span class="o">=</span><span class="n">trace_scale_output</span><span class="p">,</span>
            <span class="n">cadc_time_shift</span><span class="o">=</span><span class="n">trace_shift_out</span><span class="p">,</span>
            <span class="n">shift_cadc_to_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">neuron_structure</span><span class="o">=</span><span class="n">morph_out</span><span class="p">)</span>

        <span class="c1"># initialize weights</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">linear</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">weight_init_hidden</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">linear</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear_output</span><span class="p">):</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="o">*</span><span class="n">weight_init_output</span><span class="p">)</span>

        <span class="c1"># Device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># placeholder for (hidden) spikes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spikes</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># placeholder for current encoded inputs and output traces</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoded_input</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">traces</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spikes</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform a forward path.</span>

<span class="sd">        :param spikes: LIFObservables holding spikes as input.</span>

<span class="sd">        :return: Returns the output of the network, i.e. membrane traces of</span>
<span class="sd">            the readout neurons.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># clear spike list and traces list for each iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spikes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">traces</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Spike input</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">spikes</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">spikes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">spikes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Input -&gt; hidden</span>
        <span class="n">g1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden_0</span><span class="p">(</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">LIFObservables</span><span class="p">(</span><span class="n">spikes</span><span class="o">=</span><span class="n">inputs</span><span class="p">))</span>
        <span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_hidden_0</span><span class="p">(</span><span class="n">g1</span><span class="p">)</span>
        <span class="n">g2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden_1</span><span class="p">(</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">LIFObservables</span><span class="p">(</span><span class="n">spikes</span><span class="o">=</span><span class="n">inputs</span><span class="p">))</span>
        <span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_hidden_1</span><span class="p">(</span><span class="n">g2</span><span class="p">)</span>
        <span class="n">g3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden_2</span><span class="p">(</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">LIFObservables</span><span class="p">(</span><span class="n">spikes</span><span class="o">=</span><span class="n">inputs</span><span class="p">))</span>
        <span class="n">s3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_hidden_2</span><span class="p">(</span><span class="n">g3</span><span class="p">)</span>
        <span class="n">g4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_hidden_3</span><span class="p">(</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">LIFObservables</span><span class="p">(</span><span class="n">spikes</span><span class="o">=</span><span class="n">inputs</span><span class="p">))</span>
        <span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_hidden_3</span><span class="p">(</span><span class="n">g4</span><span class="p">)</span>

        <span class="c1"># Hidden -&gt; output</span>
        <span class="n">g5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_output_0</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
        <span class="n">g6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_output_1</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span>
        <span class="n">g7</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_output_2</span><span class="p">(</span><span class="n">s3</span><span class="p">)</span>
        <span class="n">g8</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_output_3</span><span class="p">(</span><span class="n">s4</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_output</span><span class="p">(</span><span class="n">g5</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_output</span><span class="p">(</span><span class="n">g6</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_output</span><span class="p">(</span><span class="n">g7</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_output</span><span class="p">(</span><span class="n">g8</span><span class="p">)</span>

        <span class="c1"># runtime 2 µs seconds longer for buffer</span>
        <span class="n">hxsnn</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Concat tensors of partitioned hidden layer</span>
        <span class="n">s_h</span> <span class="o">=</span> <span class="p">[</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">,</span> <span class="n">s3</span><span class="p">,</span> <span class="n">s4</span><span class="p">]</span>
        <span class="n">hidden_traces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">s_h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">membrane_cadc</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">hidden_spikes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">s_h</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">spikes</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)],</span> <span class="mi">2</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">traces</span> <span class="o">=</span> <span class="p">[</span><span class="n">hidden_traces</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">membrane_cadc</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spikes</span> <span class="o">=</span> <span class="p">[</span><span class="n">hidden_spikes</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">traces</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_proj_attrs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj_attrs</span>

    <span class="k">def</span> <span class="nf">get_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span> <span class="c1"># spikes per input per neuron</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates (and returns) the rate at which neurons fire.</span>

<span class="sd">        :returns: Firing rate per neuron and input image for all spiking</span>
<span class="sd">            neurons in the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spikes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">spikes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">spikes</span><span class="p">:</span>
            <span class="n">rate</span> <span class="o">+=</span> <span class="n">spikes</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">batch_size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="k">return</span> <span class="n">rate</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Complete model with encoder, network (snn) and decoder &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                <span class="n">network</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                <span class="n">decoder</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the model by assigning encoder, network and decoder</span>

<span class="sd">        :param encoder: Module to encode input data</span>
<span class="sd">        :param network: Network module containing layers and</span>
<span class="sd">            parameters / weights</span>
<span class="sd">        :param decoder: Module to decode network output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform forward pass through whole model, i.e.</span>
<span class="sd">        data -&gt; encoder -&gt; network -&gt; decoder -&gt; output</span>

<span class="sd">        :param inputs: tensor input data</span>

<span class="sd">        :returns: Returns tensor output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spikes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">traces</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">spikes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">traces</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scores</span>

    <span class="k">def</span> <span class="nf">regularize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_readout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">reg_bursts</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">reg_w_hidden</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">reg_w_output</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
            <span class="n">exponent</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute regularization loss for spiking activity, magnitude of</span>
<span class="sd">        weights and magnitude of max-over-time values.</span>

<span class="sd">        :param reg_bursts: prefactor of burst / hidden spike regulaization</span>
<span class="sd">        :param reg_weights_hidden: prefactor of hidden weight regularization</span>
<span class="sd">        :param reg_weights_output: prefactor of output weight regularization</span>
<span class="sd">        :param exponent: exponent in regularization terms</span>
<span class="sd">        :returns: Returns regularization terms in a tensor and their sum</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">reg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Reg readout</span>
        <span class="n">reg_scores</span> <span class="o">=</span> <span class="n">reg_readout</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span> <span class="o">**</span> <span class="n">exponent</span><span class="p">)</span>
        <span class="n">reg</span> <span class="o">+=</span> <span class="n">reg_scores</span>

        <span class="c1"># bursts (hidden spikes) regularization</span>
        <span class="n">reg_spikes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">spikes</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">spikes</span><span class="p">:</span>
            <span class="n">reg_spikes</span> <span class="o">+=</span> <span class="n">reg_bursts</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">spikes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">**</span> <span class="n">exponent</span><span class="p">)</span>
        <span class="n">reg</span> <span class="o">+=</span> <span class="n">reg_spikes</span>

        <span class="c1"># weight regularization</span>
        <span class="n">reg_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scores</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">linear</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">linear_hidden</span><span class="p">:</span>
            <span class="n">reg_weight</span> <span class="o">+=</span> <span class="n">reg_w_hidden</span> <span class="o">*</span> \
                <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span> <span class="o">**</span> <span class="n">exponent</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">linear</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">linear_output</span><span class="p">:</span>
            <span class="n">reg_weight</span> <span class="o">+=</span> <span class="n">reg_w_output</span> <span class="o">*</span> \
                <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span> <span class="o">**</span> <span class="n">exponent</span><span class="p">)</span>
        <span class="n">reg</span> <span class="o">+=</span> <span class="n">reg_weight</span>

        <span class="k">return</span> <span class="n">reg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="p">[</span><span class="n">reg_scores</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">reg_spikes</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">reg_weight</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

    <span class="k">def</span> <span class="nf">get_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates (and returns) the rate at which neurons fire.</span>

<span class="sd">        :returns: Firing rate per neuron and input image for all spiking</span>
<span class="sd">            neurons in the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">get_rate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="calibrations-and-parameters">
<h2>Calibrations and Parameters<a class="headerlink" href="#calibrations-and-parameters" title="Permalink to this headline"></a></h2>
<p>Before we set up the training functions for our model, lets take a step back and realize that the neuron parameters that are set in the model above have to be calibrated on hardware - if we are not using the mock-mode.
We will just have to set some parameters and the BSS-2 system will be calibrated implicitly.
Changing neuron parameters like the leak or threshold potential requires recalibration which takes some minutes.
Parameterizing neurons on BSS-2 is discussed in more detail in the tutorials <a class="reference internal" href="ts_00-single_neuron.html"><span class="doc">BrainScaleS-2 single neuron experiments</span></a> and <a class="reference internal" href="ts_12-hxtorch_snn_intro.html"><span class="doc">hxtorch.snn Introduction</span></a>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hxtorch.snn.parameter</span> <span class="kn">import</span> <span class="n">HXParameter</span><span class="p">,</span> <span class="n">MixedHXModelParameter</span>

<span class="c1"># Neuron parameters</span>
<span class="n">lif_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tau_syn&quot;</span><span class="p">:</span> <span class="n">HXParameter</span><span class="p">(</span><span class="mf">5.7e-6</span><span class="p">),</span>
    <span class="s2">&quot;tau_mem&quot;</span><span class="p">:</span> <span class="n">HXParameter</span><span class="p">(</span><span class="mf">6e-6</span><span class="p">),</span>
    <span class="s2">&quot;leak&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
    <span class="s2">&quot;reset&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
    <span class="s2">&quot;threshold&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">120</span><span class="p">),</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>

<span class="n">li_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;tau_syn&quot;</span><span class="p">:</span> <span class="n">HXParameter</span><span class="p">(</span><span class="mf">5.7e-6</span><span class="p">),</span>
    <span class="s2">&quot;tau_mem&quot;</span><span class="p">:</span> <span class="n">HXParameter</span><span class="p">(</span><span class="mf">6e-6</span><span class="p">),</span>
    <span class="s2">&quot;leak&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
    <span class="s2">&quot;reset&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
    <span class="s2">&quot;threshold&quot;</span><span class="p">:</span> <span class="n">MixedHXModelParameter</span><span class="p">(</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">120</span><span class="p">),</span>
    <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">}</span>


<span class="c1"># Simulation</span>
<span class="n">mock</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">weight_scale</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">trace_scale</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="c1"># Regularization parameters</span>
<span class="n">reg_bursts</span> <span class="o">=</span> <span class="mf">0.0025</span>
<span class="n">reg_weights_hidden</span> <span class="o">=</span> <span class="mf">0.0033</span>
<span class="n">reg_readout</span> <span class="o">=</span> <span class="mf">1.6e-4</span>
<span class="n">reg_weights_output</span> <span class="o">=</span> <span class="mf">0.0033</span>
<span class="n">reg_gamma</span> <span class="o">=</span> <span class="mf">0.985</span>
<span class="n">reg_step_size</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Training parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">lr</span> <span class="o">=</span> <span class="mf">0.002</span>
</pre></div>
</div>
<div class="test html-display-none highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<p>You might also return to these parameters later and choose different regularization values.</p>
</div>
<div class="section" id="training-and-testing">
<h2>Training and Testing<a class="headerlink" href="#training-and-testing" title="Permalink to this headline"></a></h2>
<p>We will now set up the training and testing methods for any model that we might choose.
The loss function will consist of the cross-entropy loss as well as the regularization terms.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span>

<span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
          <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
          <span class="n">update_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Perform training or testing for one epoch.</span>

<span class="sd">    :param model: The model to train/test.</span>
<span class="sd">    :param loader: Pytorch DataLoader instance providing training/testing</span>
<span class="sd">        data.</span>
<span class="sd">    :param optimizer: The optimizer used for weight optimization.</span>
<span class="sd">    :param epoch: Current epoch for logging.</span>
<span class="sd">    :param train: Bool indicating whether we train or evaluate the model.</span>
<span class="sd">    :update_func: A function to track data for plotting.</span>
<span class="sd">    :returns: Tuple (loss, accuracy, mean rate)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># define loss function</span>
    <span class="n">loss_func</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">train</span><span class="p">)</span> <span class="c1"># sets model in training / eval mode</span>
    <span class="n">dev</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">network</span><span class="o">.</span><span class="n">device</span>

    <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_reg_loss</span><span class="p">,</span> <span class="n">total_acc</span><span class="p">,</span> <span class="n">total_rate</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">),</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dev</span><span class="p">))</span>
        <span class="c1"># compute regularization loss and add up</span>
        <span class="n">reg_loss_b</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">regularize</span><span class="p">(</span>
            <span class="n">reg_readout</span><span class="p">,</span> <span class="n">reg_bursts</span> <span class="o">*</span> <span class="n">reg_gamma</span> <span class="o">**</span>\
                            <span class="p">((</span><span class="nb">int</span><span class="p">)((</span><span class="n">epoch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">reg_step_size</span><span class="p">)),</span>
            <span class="n">reg_weights_hidden</span><span class="p">,</span> <span class="n">reg_weights_output</span><span class="p">,</span> <span class="n">exponent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">total_reg_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg_loss_b</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># compute total loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dev</span><span class="p">))</span> <span class="o">+</span> <span class="n">reg_loss_b</span>
        <span class="n">total_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">train</span><span class="p">:</span> <span class="c1"># backpropagation</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Train accuracy</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">total_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="c1"># Firing rates</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_rate</span><span class="p">()</span>
        <span class="n">total_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rate</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">loss_reg</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">reg_loss_b</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">acc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rate</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">total_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">total_acc</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">total_rate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">total_rate</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    <span class="n">total_reg_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">total_reg_loss</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

    <span class="c1"># Update data for plotting</span>
    <span class="n">update_func</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">total_loss</span><span class="p">,</span> <span class="n">acc</span><span class="o">=</span><span class="n">total_acc</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">total_rate</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train: </span><span class="si">{</span><span class="n">train</span><span class="si">}</span><span class="s2">, Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss </span><span class="si">{</span><span class="n">total_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy </span><span class="si">{</span><span class="n">total_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">total_acc</span><span class="p">,</span> <span class="n">total_rate</span><span class="p">,</span> <span class="n">total_reg_loss</span>
</pre></div>
</div>
</div>
<div class="section" id="final-setup-and-the-training-loop">
<h2>Final Setup And The Training Loop<a class="headerlink" href="#final-setup-and-the-training-loop" title="Permalink to this headline"></a></h2>
<p>We can now approach the final setup for our training.
For the mapping between the hardware measurements and the software simulation, we will initiate a calibration and measure the scaling of the weights and traces.
This is necessary as we assume <code class="docutils literal notranslate"><span class="pre">threshold</span> <span class="pre">=</span> <span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">leak,</span> <span class="pre">reset</span> <span class="pre">=</span> <span class="pre">0</span></code> in software.
To ensure a correspondance between the gradient in software and the neural dynamics on hardware, a transformation of the software weights to hardware weights and a transformation of membrane observables on hardware to membrane traces in software need to be found (therefore: <code class="docutils literal notranslate"><span class="pre">get_weight_scaling(...)</span></code>).
The mapping between hardware dynamics and the dynamics assumed for computing gradients in explained and visualized in <a class="reference internal" href="ts_12-hxtorch_snn_intro.html"><span class="doc">hxtorch.snn Introduction</span></a>.</p>
<p>The calibration might take a while so feel free to read on until it is finished.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">hxtorch.spiking.utils.dynamic_range.weight_scaling</span> <span class="kn">import</span> <span class="n">get_weight_scaling</span>
<span class="kn">from</span> <span class="nn">hxtorch.spiking.utils.dynamic_range.threshold</span> <span class="kn">import</span> <span class="n">get_trace_scaling</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hxtorch</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">set_loglevel</span><span class="p">(</span>
    <span class="n">hxtorch</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;grenade&quot;</span><span class="p">),</span> <span class="n">hxtorch</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">LogLevel</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">mock</span><span class="p">:</span>
    <span class="c1"># Measure weight scaling SW - HW weight</span>
    <span class="n">weight_scale_hidden</span> <span class="o">=</span> <span class="n">get_weight_scaling</span><span class="p">(</span>
        <span class="n">lif_params</span><span class="p">,</span> <span class="n">weight_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">neuron_structure</span><span class="o">=</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">expand_horizontally</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">weight_scale_output</span> <span class="o">=</span> <span class="n">get_weight_scaling</span><span class="p">(</span>
        <span class="n">lif_params</span><span class="p">,</span> <span class="n">weight_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">neuron_structure</span><span class="o">=</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expand_horizontally</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Weight scale hidden </span><span class="si">{</span><span class="n">weight_scale_hidden</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;weight scale out </span><span class="si">{</span><span class="n">weight_scale_output</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="c1"># Measure trace scaling SW - HW</span>
    <span class="n">trace_scale_hidden</span> <span class="o">=</span> <span class="n">get_trace_scaling</span><span class="p">(</span>
        <span class="n">lif_params</span><span class="p">,</span> <span class="n">neuron_structure</span><span class="o">=</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">expand_horizontally</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">trace_scale_output</span> <span class="o">=</span> <span class="n">get_trace_scaling</span><span class="p">(</span>
        <span class="n">lif_params</span><span class="p">,</span> <span class="n">neuron_structure</span><span class="o">=</span><span class="n">hxsnn</span><span class="o">.</span><span class="n">morphology</span><span class="o">.</span><span class="n">SingleCompartmentNeuron</span><span class="p">(</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">expand_horizontally</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Trace scale hidden </span><span class="si">{</span><span class="n">trace_scale_hidden</span><span class="si">}</span><span class="s2">, &quot;</span>
        <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;trace scale out </span><span class="si">{</span><span class="n">trace_scale_output</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">w</span>
<span class="kn">from</span> <span class="nn">_static.tutorial.partitioning_plots</span> <span class="kn">import</span> <span class="n">plot_training</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">ttfs_encode</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">SNN</span><span class="p">(</span><span class="n">lif_params</span><span class="o">=</span><span class="n">lif_params</span><span class="p">,</span>
        <span class="n">li_params</span><span class="o">=</span><span class="n">li_params</span><span class="p">,</span>
        <span class="n">mock</span><span class="o">=</span><span class="n">mock</span><span class="p">,</span>
        <span class="n">dt</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">weight_init_hidden</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
        <span class="n">weight_init_output</span><span class="o">=</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
        <span class="n">weight_scale_hidden</span><span class="o">=</span><span class="n">weight_scale_hidden</span><span class="p">,</span>
        <span class="n">weight_scale_output</span><span class="o">=</span><span class="n">weight_scale_output</span><span class="p">,</span>
        <span class="n">trace_scale_hidden</span><span class="o">=</span><span class="n">trace_scale_hidden</span><span class="p">,</span>
        <span class="n">trace_scale_output</span><span class="o">=</span><span class="n">trace_scale_output</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">),</span>
    <span class="n">partial</span><span class="p">(</span><span class="n">decode</span><span class="p">,</span> <span class="n">trace_scaling</span><span class="o">=</span><span class="mf">3.</span><span class="p">))</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.97</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="the-training-loop">
<h2>The Training Loop<a class="headerlink" href="#the-training-loop" title="Permalink to this headline"></a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">w</span>

<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">_static.tutorial.partitioning_plots</span> <span class="kn">import</span> <span class="n">plot_training</span>

<span class="c1"># initialize hardware</span>
<span class="n">hxtorch</span><span class="o">.</span><span class="n">init_hardware</span><span class="p">()</span>

<span class="c1"># plotting during training</span>
<span class="n">update_plot</span><span class="p">,</span> <span class="n">update_train_data</span><span class="p">,</span> <span class="n">update_test_data</span> <span class="o">=</span> <span class="n">plot_training</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="k">with</span> <span class="n">output</span><span class="p">:</span>
    <span class="n">update_plot</span><span class="p">()</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

    <span class="n">loss_train</span><span class="p">,</span> <span class="n">acc_train</span><span class="p">,</span> <span class="n">rate_train</span><span class="p">,</span> <span class="n">regs_train</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">update_train_data</span><span class="p">)</span>
    <span class="n">loss_test</span><span class="p">,</span> <span class="n">acc_test</span><span class="p">,</span> <span class="n">rate_test</span><span class="p">,</span> <span class="n">regs_test</span> <span class="o">=</span> <span class="n">run_epoch</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">update_test_data</span><span class="p">)</span>

    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Refresh plot</span>
    <span class="n">output</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
        <span class="n">update_plot</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
        <span class="n">loss_test</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">loss_test</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">acc_test</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">acc_test</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">hxtorch</span><span class="o">.</span><span class="n">release_hardware</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ts_12-hxtorch_snn_intro.html" class="btn btn-neutral float-left" title="hxtorch.snn Introduction" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tp_00-introduction.html" class="btn btn-neutral float-right" title="Introduction to matrix multiplication" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Electronic Vision(s).</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>