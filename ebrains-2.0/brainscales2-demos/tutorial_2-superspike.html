

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Learning with the SuperSpike rule &mdash; BrainScaleS-2 Documentation 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/visions.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction to matrix multiplication" href="tutorial_3-hagen_intro.html" />
    <link rel="prev" title="BrainScaleS-2 single neuron experiments" href="tutorial_1-single_neuron.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> BrainScaleS-2 Documentation
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Demos &amp; Examples</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="tutorial_0-welcome.html">Welcome to the BrainScaleS-2 Tutorial</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="tutorial_1-single_neuron.html">BrainScaleS-2 single neuron experiments</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Learning with the SuperSpike rule</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-spiking-networks-with-surrogate-gradients">Training spiking networks with surrogate gradients</a></li>
<li class="toctree-l4"><a class="reference internal" href="#helper-functions">Helper functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-network-in-pynn">Define network in PyNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="#construct-poisson-input-spike-trains">Construct Poisson input spike trains</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generating-a-taget-spike-train">Generating a taget spike train</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-superspike-learning-rule">The SuperSpike learning rule</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-the-network">Training the network</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_3-hagen_intro.html">Introduction to matrix multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_4-hagen_properties.html">Exploring the analog MAC operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_5-plasticity_rate_coding.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_6-multicompartment.html">Structured Neurons</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_0-welcome.html#executing-the-notebooks">Executing the Notebooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_0-welcome.html#shared-hardware-resources">Shared Hardware Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorial_0-welcome.html#final-test-hardware-execution">Final test: Hardware Execution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_1-single_neuron.html">BrainScaleS-2 single neuron experiments</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Learning with the SuperSpike rule</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training-spiking-networks-with-surrogate-gradients">Training spiking networks with surrogate gradients</a></li>
<li class="toctree-l3"><a class="reference internal" href="#helper-functions">Helper functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#define-network-in-pynn">Define network in PyNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#construct-poisson-input-spike-trains">Construct Poisson input spike trains</a></li>
<li class="toctree-l3"><a class="reference internal" href="#generating-a-taget-spike-train">Generating a taget spike train</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#the-superspike-learning-rule">The SuperSpike learning rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-network">Training the network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Exercises</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_3-hagen_intro.html">Introduction to matrix multiplication</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_4-hagen_properties.html">Exploring the analog MAC operation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_5-plasticity_rate_coding.html">BrainScaleS-2 on-chip plasticity experiment</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_6-multicompartment.html">Structured Neurons</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_7-yin_yang_itl.html">Train DNNs on BrainScaleS-2</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_8-dynamic_range.html">Exploring the dynamic range</a></li>
<li class="toctree-l2"><a class="reference internal" href="wolke7_networks.html">Neuronenverbindungen - Synapsen</a></li>
<li class="toctree-l2"><a class="reference internal" href="wolke7_networks.html#synapsennetzwerke">Synapsennetzwerke</a></li>
<li class="toctree-l2"><a class="reference internal" href="fp_0-welcome.html">Welcome to the Advanced Physics Lab for Physicists by the Electronic Vision(s) Group</a></li>
<li class="toctree-l2"><a class="reference internal" href="fp_pynn_introduction.html">Introduction to PyNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="fp_binary_operations.html">Binary operations using spiking neurons</a></li>
<li class="toctree-l2"><a class="reference internal" href="fp_sudoku.html">Sudoku</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apis.html">API Reference</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">BrainScaleS-2 Documentation</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Welcome to the BrainScaleS-2 Demos &amp; Examples!</a> &raquo;</li>
        
          <li><a href="tutorial_0-welcome.html">Welcome to the BrainScaleS-2 Tutorial</a> &raquo;</li>
        
      <li>Learning with the SuperSpike rule</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/brainscales2-demos/tutorial_2-superspike.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="learning-with-the-superspike-rule">
<span id="superspike"></span><h1>Learning with the SuperSpike rule<a class="headerlink" href="#learning-with-the-superspike-rule" title="Permalink to this headline">¶</a></h1>
<p>In the previous example, you accustomed yourself with BrainScaleS-2’s
analog neuron circuit. Here, we will build on this knowledge and train a
single neuron to reproduce a pre-defined target spike train. For this
purpose, we will implement the SuperSpike learning rule [1] to minimize
the van Rossum distance between the targets and the spikes produced by
our neuron.</p>
<p>Specifically, we will</p>
<ul class="simple">
<li><p>set up a network using PyNN,</p></li>
<li><p>generate a target spike train,</p></li>
<li><p>re-initialize the network’s weights,</p></li>
<li><p>and implement an in-the-loop training scheme directly in Python.</p></li>
</ul>
<div class="section" id="training-spiking-networks-with-surrogate-gradients">
<h2>Training spiking networks with surrogate gradients<a class="headerlink" href="#training-spiking-networks-with-surrogate-gradients" title="Permalink to this headline">¶</a></h2>
<p>The discontinuity introduced by the spiking threshold presents
challenges when it comes to training networks of spiking neurons with
gradient-based methods, especially when employing sparse coding
techniques far away from the rate coding limit. Recently, efforts have
been made by “smoothing” out the true activation function for the
backward pass [1,2,3,4,5]. These “surrogate gradients” allow to easily
train feed-forward as well as recurrent SNNs on common benchmark datasets.</p>
<p>For BrainScaleS-2, we have developed a powerful in-the-loop training
scheme that allows to perform backpropagation through time using
auto-differentiation frameworks [6]. With a feed-forward network, we
reached 97.6 % test accuracy on the MNIST dataset. The accelerated
emulation allowed to classify more than 85k images per second with an energy
budget of only 2.4 μJ per image. Moreover, we trained a recurrent SNN on
natural language data from the SHD dataset [7].</p>
<p>In this example, we will not go that far. Instead, we will implement the
forward-integrated SuperSpike learning rule on a simple artifical input
pattern. In case you are interested, though, please refer to the original
publication.</p>
<div class="admonition-references-for-further-reading admonition">
<p class="admonition-title">References for further reading</p>
<ol class="arabic simple">
<li><p>Zenke, Friedemann, and Surya Ganguli. “Superspike: Supervised
learning in multilayer spiking neural networks.” <em>Neural computation</em>
30.6 (2018): 1514-1541.</p></li>
<li><p>Neftci, Emre O., Hesham Mostafa, and Friedemann Zenke. “Surrogate
gradient learning in spiking neural networks: Bringing the power of
gradient-based optimization to spiking neural networks.” IEEE Signal
Processing Magazine 36.6 (2019): 51-63.</p></li>
<li><p>Bellec, Guillaume, et al. “A solution to the learning dilemma for
recurrent networks of spiking neurons.” Nature communications 11.1
(2020): 1-15.</p></li>
<li><p>Bohte, Sander M. “Error-backpropagation in networks of fractionally
predictive spiking neurons.” International Conference on Artificial
Neural Networks. Springer, Berlin, Heidelberg, 2011.</p></li>
<li><p>Esser, Steven K., et al. “Convolutional networks for fast,
energy-efficient neuromorphic computing.” Proceedings of the national
academy of sciences 113.41 (2016): 11441-11446.</p></li>
<li><p>Cramer, Benjamin, et al. “Surrogate gradients for analog neuromorphic
computing” Proceedings of the national academy of sciences 119.4 (2022)</p></li>
<li><p>Cramer, Benjamin, et al. “The Heidelberg Spiking Data Sets for the
Systematic Evaluation of Spiking Neural Networks.” IEEE Transactions
on Neural Networks and Learning Systems (2020).</p></li>
</ol>
</div>
<p>In order to use the microscheduler we have to set some environment variables first:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">_static.common.helpers</span> <span class="kn">import</span> <span class="n">setup_hardware_client</span>
<span class="n">setup_hardware_client</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">w</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">suppress</span>
<span class="k">with</span> <span class="n">suppress</span><span class="p">(</span><span class="ne">IOError</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;_static/matplotlibrc&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pynn_brainscales.brainscales2</span> <span class="k">as</span> <span class="nn">pynn</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<p>Let’s define some helper functions for plotting.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">create_figure</span><span class="p">():</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;norm. membrane&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">duration</span> <span class="o">*</span> <span class="mf">1e6</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([])</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>

    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;time / μs&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;error trace&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">duration</span> <span class="o">*</span> <span class="mf">1e6</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span>

<span class="k">def</span> <span class="nf">update_figure</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="o">*</span><span class="n">data</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">get_lines</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1e6</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">display</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="define-network-in-pynn">
<h2>Define network in PyNN<a class="headerlink" href="#define-network-in-pynn" title="Permalink to this headline">¶</a></h2>
<p>First, we will set up some variables determining the network structure. We will
furthermore define the binning of the stimuli and the later calculation of the
weight updates.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_inputs</span> <span class="o">=</span> <span class="mi">60</span>

<span class="n">duration</span> <span class="o">=</span> <span class="mf">200e-6</span>  <span class="c1"># s in wallclock time</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1e-6</span>

<span class="n">n_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">duration</span> <span class="o">/</span> <span class="n">dt</span><span class="p">)</span>

<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_steps</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">dt</span>
</pre></div>
</div>
<p>Before we define our network, we load the default calibration.</p>
<p>A default calibration is generated for every setup every night.
We save the nightly calibration in two variables such that we can use it later when we define our neuronal network.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">_static.common.helpers</span> <span class="kn">import</span> <span class="n">get_nightly_calibration</span>
<span class="n">calib</span> <span class="o">=</span> <span class="n">get_nightly_calibration</span><span class="p">()</span>
</pre></div>
</div>
<p>Now, we can define the network itself using PyNN.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setup PyNN and inect calibration data</span>
<span class="n">pynn</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">initial_config</span><span class="o">=</span><span class="n">calib</span><span class="p">)</span>

<span class="c1"># create output population (one neuron) and record its observables</span>
<span class="n">pop_output</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">HXNeuron</span><span class="p">())</span>
<span class="n">pop_output</span><span class="o">.</span><span class="n">record</span><span class="p">([</span><span class="s2">&quot;spikes&quot;</span><span class="p">,</span> <span class="s2">&quot;v&quot;</span><span class="p">])</span>

<span class="c1"># create spike sources</span>
<span class="n">pop_input</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Population</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">pynn</span><span class="o">.</span><span class="n">cells</span><span class="o">.</span><span class="n">SpikeSourceArray</span><span class="p">(</span><span class="n">spike_times</span><span class="o">=</span><span class="p">[]))</span>

<span class="c1"># define two projections (excitatory + inhibitory) to allow signed weights</span>
<span class="n">synapse_exc</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">standardmodels</span><span class="o">.</span><span class="n">synapses</span><span class="o">.</span><span class="n">StaticSynapse</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">synapse_inh</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">standardmodels</span><span class="o">.</span><span class="n">synapses</span><span class="o">.</span><span class="n">StaticSynapse</span><span class="p">(</span><span class="n">weight</span><span class="o">=-</span><span class="mi">42</span><span class="p">)</span>
<span class="n">projection_io_inh</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Projection</span><span class="p">(</span><span class="n">pop_input</span><span class="p">,</span> <span class="n">pop_output</span><span class="p">,</span>
                             <span class="n">pynn</span><span class="o">.</span><span class="n">AllToAllConnector</span><span class="p">(),</span>
                             <span class="n">synapse_type</span><span class="o">=</span><span class="n">synapse_inh</span><span class="p">,</span>
                             <span class="n">receptor_type</span><span class="o">=</span><span class="s2">&quot;inhibitory&quot;</span><span class="p">)</span>
<span class="n">projection_io_exc</span> <span class="o">=</span> <span class="n">pynn</span><span class="o">.</span><span class="n">Projection</span><span class="p">(</span><span class="n">pop_input</span><span class="p">,</span> <span class="n">pop_output</span><span class="p">,</span>
                             <span class="n">pynn</span><span class="o">.</span><span class="n">AllToAllConnector</span><span class="p">(),</span>
                             <span class="n">synapse_type</span><span class="o">=</span><span class="n">synapse_exc</span><span class="p">,</span>
                             <span class="n">receptor_type</span><span class="o">=</span><span class="s2">&quot;excitatory&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>To work around Dale’s law, we have to merge two projections together to
form signed synapses. The following function assigns the signed weight
matrix to the two projections.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">w_max</span><span class="o">=</span><span class="mi">63</span><span class="p">):</span>
    <span class="c1"># limit weights to hw boundaries</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="o">-</span><span class="n">w_max</span><span class="p">,</span> <span class="n">w_max</span><span class="p">)</span>

    <span class="n">integer_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">w_exc</span> <span class="o">=</span> <span class="n">integer_weights</span> <span class="o">*</span> <span class="p">(</span><span class="n">integer_weights</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">w_inh</span> <span class="o">=</span> <span class="n">integer_weights</span> <span class="o">*</span> <span class="p">(</span><span class="n">integer_weights</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">projection_io_inh</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">w_inh</span><span class="p">)</span>
    <span class="n">projection_io_exc</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">weight</span><span class="o">=</span><span class="n">w_exc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="construct-poisson-input-spike-trains">
<h2>Construct Poisson input spike trains<a class="headerlink" href="#construct-poisson-input-spike-trains" title="Permalink to this headline">¶</a></h2>
<p>To generate (fixed-seed) random inputs, we calculate binned spike trains
according to a Bernoulli process.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123456</span><span class="p">)</span>

<span class="n">freq</span> <span class="o">=</span> <span class="mf">10e3</span>  <span class="c1"># Hz (remember the acceleration factor!)</span>
<span class="n">input_spikes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">stimuli_dense</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">freq</span> <span class="o">*</span> <span class="n">dt</span>
<span class="n">stimuli_dense</span><span class="p">[:,</span> <span class="p">(</span><span class="n">time</span> <span class="o">&gt;</span> <span class="p">(</span><span class="n">duration</span> <span class="o">-</span> <span class="mf">20e-6</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">stimuli_dense</span><span class="p">:</span>
    <span class="n">input_spikes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">s</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dt</span> <span class="o">*</span> <span class="mf">1e3</span><span class="p">)</span> <span class="c1"># convert to ms for pyNN</span>

<span class="n">pop_input</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">spike_times</span><span class="o">=</span><span class="n">input_spikes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="generating-a-taget-spike-train">
<h2>Generating a taget spike train<a class="headerlink" href="#generating-a-taget-spike-train" title="Permalink to this headline">¶</a></h2>
<p>Now, we can inject the previously defined input spike trains into our target
neuron. For this purpose, we first randomly initialize the synaptic weights.</p>
<p>The resulting output spikes will later be used as a target spike train.
The difficulty of the task will depend on the number and timing of target
spikes.</p>
<div class="section" id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Play around with the mean and standard deviation of the weight distribution
and observe the output of the neuron. Try to get the neuron to emit
approximately 3 to 4 spikes. This spike train will later be used as a target
spike train <span class="math notranslate nohighlight">\(\hat S_i\)</span>.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@w</span><span class="o">.</span><span class="n">interact</span><span class="p">(</span>
    <span class="n">weight_mean</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span>
        <span class="mi">10</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">weight_std</span><span class="o">=</span><span class="n">w</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="p">)</span>
<span class="k">def</span> <span class="nf">experiment</span><span class="p">(</span><span class="n">weight_mean</span><span class="p">,</span> <span class="n">weight_std</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">v_mem</span><span class="p">,</span> <span class="n">target_spikes</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">weight_mean</span><span class="p">,</span> <span class="n">weight_std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">pynn</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">duration</span> <span class="o">*</span> <span class="mf">1e3</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">pop_output</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>

    <span class="n">target_spikes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">segments</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spiketrains</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e3</span>  <span class="c1"># convert ms to s</span>

    <span class="n">membrane</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">segments</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">irregularlysampledsignals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">v_mem</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">membrane</span><span class="o">.</span><span class="n">times</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">,</span> <span class="n">membrane</span><span class="o">.</span><span class="n">magnitude</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="o">*</span><span class="mf">1e6</span><span class="p">,</span> <span class="n">v_mem</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">duration</span><span class="o">*</span><span class="mf">1e6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;time / μs&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;membrane potential / LSB&quot;</span><span class="p">)</span>
    <span class="n">pynn</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">experiment</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>  <span class="c1"># needed for testing</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/superspike_target.png"><img alt="../_images/superspike_target.png" class="solution align-center" src="../_images/superspike_target.png" style="width: 90%;" /></a>
<p>Extract the dynamic range from the above plot to normalize the membrane
potential for calculating the surrogate gradient.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">v_zero</span> <span class="o">=</span> <span class="n">v_mem</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
<span class="n">dynamic_range</span> <span class="o">=</span> <span class="n">v_mem</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">v_zero</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="the-superspike-learning-rule">
<h2>The SuperSpike learning rule<a class="headerlink" href="#the-superspike-learning-rule" title="Permalink to this headline">¶</a></h2>
<p>The SuperSpike learning rule was derived to perform gradient descent on
the van Rossum distance</p>
<div class="math notranslate nohighlight">
\[\mathcal{L} = \frac{1}{2} \int_{-\infty}^t \mathrm{d}s \, \left[ \left( \alpha * \hat S_i(s) - \alpha * S_i(s) \right) \right]^2 =: \frac{1}{2} \int_{-\infty}^t \mathrm{d}s \, e_i(s)^2\]</div>
<p>between the current spike train <span class="math notranslate nohighlight">\(S_i\)</span> and the target spike train <span class="math notranslate nohighlight">\(\hat S_i\)</span>.
Here, <span class="math notranslate nohighlight">\(\alpha\)</span> is the kernel used to calculate the van Rossum distance and <span class="math notranslate nohighlight">\(e_i(s)\)</span> the error signal.
The weight update rule can in the end be written as</p>
<div class="math notranslate nohighlight">
\[\Delta w_{ij}^k = \eta \int \mathrm{d}s \, e_i(s) \cdot \alpha * \left[ \sigma^\prime (v_i(s)) \cdot (\epsilon * S_j)(s) \right] \,\]</div>
<p>where <span class="math notranslate nohighlight">\(\sigma^\prime\)</span> represents the
surrogate gradient of membrane potential <span class="math notranslate nohighlight">\(v_i\)</span>, and
<span class="math notranslate nohighlight">\(\epsilon\)</span> the exponentially decaying kernel of the synaptic
currents.</p>
<p>The integral consists of a Hebbian contribution which combines the
surrogate gradient of the membrane potential with the exponentially
decaying synaptic currents as eligibility traces. This term is augmented
by the error signal as a third factor, which can be calculated through
backpropagation for multi-layer networks.</p>
<p>The learning rule can be forward-integrated alongside the neuronal
dynamics, which makes it particularly interesting for online learning
applications.</p>
<p>Let’s have a look at the surrogate function <span class="math notranslate nohighlight">\(\sigma^\prime\)</span> as a function of
the steepness paramter <span class="math notranslate nohighlight">\(\beta\)</span>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">superspike</span><span class="p">(</span><span class="n">v_m</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">5.0</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">v_m</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)),</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">for</span> <span class="n">beta</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="mi">4</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">superspike</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;beta = </span><span class="si">{</span><span class="n">beta</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;normalized membrane potential&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;surrogate gradient&quot;</span><span class="p">);</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/superspike_gradient.png"><img alt="../_images/superspike_gradient.png" class="solution align-center" src="../_images/superspike_gradient.png" style="width: 90%;" /></a>
<p>The SuperSpike learning rules requires estimates of the neuro-synaptic
time constants. Here, we use the same values as targeted for the deployed
calibration data.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tau_mem</span> <span class="o">=</span> <span class="mf">10e-6</span>
<span class="n">tau_syn</span> <span class="o">=</span> <span class="mf">5e-6</span>
</pre></div>
</div>
<p>Construct kernels for the learning rule, including the van Rossum
distance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_kernel_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">100e-6</span> <span class="o">/</span> <span class="n">dt</span><span class="p">)</span>
<span class="n">n_kernel_steps</span> <span class="o">=</span> <span class="n">n_kernel_steps</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">n_kernel_steps</span> <span class="o">%</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">kernel_psc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_kernel_steps</span><span class="p">)</span>
<span class="n">kernel_psc</span><span class="p">[</span><span class="o">-</span><span class="nb">int</span><span class="p">(</span><span class="n">kernel_psc</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">kernel_psc</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">tau_syn</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>

<span class="n">kernel_psp</span> <span class="o">=</span> <span class="n">kernel_psc</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">kernel_psp</span><span class="p">[</span><span class="o">-</span><span class="nb">int</span><span class="p">(</span><span class="n">kernel_psp</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">):]</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">kernel_psp</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">tau_mem</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>

<span class="n">kernel_vrd</span> <span class="o">=</span> <span class="n">kernel_psp</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="training-the-network">
<h2>Training the network<a class="headerlink" href="#training-the-network" title="Permalink to this headline">¶</a></h2>
<p>We can now implement above’s weight update expression in Python and use it
to train our network to replicate the target spike train generated above.</p>
<div class="section" id="id1">
<h3>Exercises<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Train the network for different target spike trains (<span class="math notranslate nohighlight">\(\hat S_i\)</span>). For that purpose,
modify above’s cell for the target generation (e.g. seed, firing rate,
weights, …).</p></li>
<li><p>Play around with the hyper parameters such as the learning rate (<cite>eta</cite>).</p></li>
<li><p>How does the steepness of the surrogate gradient (<cite>beta</cite>) affect learning
performance?</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">create_figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">Output</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

<span class="c1"># plot target spikes</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">target_spikes</span><span class="p">:</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">t</span> <span class="o">*</span> <span class="mf">1e6</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># define hyperparameters</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">20.</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">5.</span>

<span class="c1"># initialize weights</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># iterate over multiple training &quot;epochs&quot;</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
    <span class="c1"># assign weights to PyNN projections</span>
    <span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># run the emulation</span>
    <span class="n">pynn</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">duration</span> <span class="o">*</span> <span class="mf">1e3</span><span class="p">)</span> <span class="c1"># convert to ms for PyNN</span>

    <span class="c1"># retrieve data</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pop_output</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">segments</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">spiketrains</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">1e3</span> <span class="c1"># convert to SI units (s)</span>
    <span class="n">membrane</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">segments</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">irregularlysampledsignals</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># resample and normalize mebrane trace</span>
    <span class="n">v_mem</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">membrane</span><span class="o">.</span><span class="n">times</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">,</span> <span class="n">membrane</span><span class="o">.</span><span class="n">magnitude</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">v_zero</span><span class="p">)</span> <span class="o">/</span> <span class="n">dynamic_range</span>

    <span class="c1"># reset pyNN state</span>
    <span class="n">pynn</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="c1"># compute van-Rossum distance as error signal</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">target_spikes</span><span class="p">,</span> <span class="n">bins</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">spikes</span><span class="p">,</span> <span class="n">bins</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">kernel_vrd</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>

    <span class="n">output</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">output</span><span class="p">:</span>
        <span class="n">update_figure</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">v_mem</span><span class="p">),</span> <span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">error</span><span class="p">))</span>

    <span class="c1"># calculate weight updates</span>
    <span class="n">dw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_inputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">):</span>
        <span class="n">eligibility</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">stimuli_dense</span><span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="p">:],</span> <span class="n">kernel_psc</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="n">integrand</span> <span class="o">=</span> <span class="n">error</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span>
            <span class="n">superspike</span><span class="p">(</span><span class="n">v_mem</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">eligibility</span><span class="p">,</span>
            <span class="n">kernel_psp</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">)</span>
        <span class="n">dw</span><span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">integrand</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_steps</span>

    <span class="c1"># save the loss for later plotting</span>
    <span class="n">loss</span><span class="p">[</span><span class="n">e</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>

    <span class="c1"># apply weight update</span>
    <span class="n">weights</span> <span class="o">+=</span> <span class="n">dw</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/superspike_training.png"><img alt="../_images/superspike_training.png" class="solution align-center" src="../_images/superspike_training.png" style="width: 90%;" /></a>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;loss&quot;</span><span class="p">);</span>
</pre></div>
</div>
<a class="solution reference internal image-reference" href="../_images/superspike_loss.png"><img alt="../_images/superspike_loss.png" class="solution align-center" src="../_images/superspike_loss.png" style="width: 90%;" /></a>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="tutorial_3-hagen_intro.html" class="btn btn-neutral float-right" title="Introduction to matrix multiplication" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="tutorial_1-single_neuron.html" class="btn btn-neutral float-left" title="BrainScaleS-2 single neuron experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, Electronic Vision(s).

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>